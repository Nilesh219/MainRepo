{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16a62891-6ab4-4c0f-a90b-5a4c6d3617b4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "statsmodels.tsa.holtwinters.model.ExponentialSmoothing() argument after ** must be a mapping, not range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 39\u001b[0m\n\u001b[0;32m     37\u001b[0m best_mse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)  \u001b[38;5;66;03m# Initialize to high value\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m param_grid\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m---> 39\u001b[0m     model \u001b[38;5;241m=\u001b[39m ExponentialSmoothing(train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquantity\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train_index, val_index \u001b[38;5;129;01min\u001b[39;00m tscv\u001b[38;5;241m.\u001b[39msplit(train):\n\u001b[0;32m     41\u001b[0m         model_fit \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(train\u001b[38;5;241m.\u001b[39miloc[train_index])\n",
      "\u001b[1;31mTypeError\u001b[0m: statsmodels.tsa.holtwinters.model.ExponentialSmoothing() argument after ** must be a mapping, not range"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "\n",
    "# Assuming your data is in a pandas dataframe called 'df'\n",
    "# with 'date' as the date column and 'quantity' as the quantity column\n",
    "df = pd.read_csv('new_df.csv')\n",
    "\n",
    "# Convert the 'date' column to datetime format if it's not already\n",
    "df['everyday'] = pd.to_datetime(df['everyday'])\n",
    "\n",
    "# Set the date column as the index\n",
    "df.set_index('everyday', inplace=True)\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets (optional)\n",
    "# You can experiment with different split ratios\n",
    "train_size = int(len(df) * 0.8)\n",
    "train, test = df[:train_size], df[train_size:]\n",
    "\n",
    "# Define hyperparameter search space (optional)\n",
    "# Experiment with different values for these parameters\n",
    "param_grid = {\n",
    "    'seasonal_periods': range(2, 13),  # Try different seasonality periods\n",
    "    'trend': ['additive', 'multiplicative']  # Try both additive and multiplicative trends\n",
    "}\n",
    "\n",
    "# Time Series Split for cross-validation (handles time order)\n",
    "tscv = TimeSeriesSplit(n_splits=5)  # Adjust n_splits for desired folds\n",
    "\n",
    "# Manual hyperparameter tuning loop (optional)\n",
    "# Iterate through param_grid and fit models for each parameter combination\n",
    "\n",
    "best_mse = float('inf')  # Initialize to high value\n",
    "for params in param_grid.values():\n",
    "    model = ExponentialSmoothing(train['quantity'], **params)\n",
    "    for train_index, val_index in tscv.split(train):\n",
    "        model_fit = model.fit(train.iloc[train_index])\n",
    "        mse = ((train.iloc[val_index] - model_fit.predict(start=val_index[0], end=val_index[-1]))**2).mean()\n",
    "        if mse < best_mse:\n",
    "            best_mse = mse\n",
    "            best_model = model_fit\n",
    "            best_params = params\n",
    "\n",
    "# Generate forecasts for 3 months (90 days)\n",
    "future_dates = train.index[-1] + pd.DateOffset(days=90)\n",
    "forecast = best_model.predict(start=train.index[-1], end=future_dates)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) on the test set (optional)\n",
    "mse = ((test['quantity'] - best_model.predict(start=test.index[0], end=test.index[-1]))**2).mean()\n",
    "rmse = np.sqrt(mse)  # Calculate RMSE from MSE\n",
    "print('Mean Squared Error:', round(mse, 2))\n",
    "print('Root Mean Squared Error:', round(rmse, 2))\n",
    "\n",
    "# Visualize actual vs predicted values\n",
    "plt.figure(figsize=(12, 6))  # Adjust figure size for better visualization\n",
    "train['quantity'].plot(label='Actual')\n",
    "forecast.plot(label='Forecast', alpha=0.7)\n",
    "plt.legend()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Quantity')\n",
    "plt.title('Actual vs. Forecasted Quantity')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c8bf521-4c84-4b07-b299-e69b26a6e26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: statsmodels in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.14.1)\n",
      "Requirement already satisfied: numpy<2,>=1.18 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from statsmodels) (1.24.2)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from statsmodels) (1.11.3)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from statsmodels) (2.0.0)\n",
      "Requirement already satisfied: patsy>=0.5.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from statsmodels) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from statsmodels) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas!=2.1.0,>=1.0->statsmodels) (2023.3)\n",
      "Requirement already satisfied: six in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from patsy>=0.5.4->statsmodels) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12348bdd-3867-4bf5-8ec9-0903447beb58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
