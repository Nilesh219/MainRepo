{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Competition for House Prices: Advanced Regression Techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSZoning\n",
       "RL         1151\n",
       "RM          218\n",
       "FV           65\n",
       "RH           16\n",
       "C (all)      10\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MSZoning'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 81 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Id             1460 non-null   int64  \n",
      " 1   MSSubClass     1460 non-null   int64  \n",
      " 2   MSZoning       1460 non-null   object \n",
      " 3   LotFrontage    1201 non-null   float64\n",
      " 4   LotArea        1460 non-null   int64  \n",
      " 5   Street         1460 non-null   object \n",
      " 6   Alley          91 non-null     object \n",
      " 7   LotShape       1460 non-null   object \n",
      " 8   LandContour    1460 non-null   object \n",
      " 9   Utilities      1460 non-null   object \n",
      " 10  LotConfig      1460 non-null   object \n",
      " 11  LandSlope      1460 non-null   object \n",
      " 12  Neighborhood   1460 non-null   object \n",
      " 13  Condition1     1460 non-null   object \n",
      " 14  Condition2     1460 non-null   object \n",
      " 15  BldgType       1460 non-null   object \n",
      " 16  HouseStyle     1460 non-null   object \n",
      " 17  OverallQual    1460 non-null   int64  \n",
      " 18  OverallCond    1460 non-null   int64  \n",
      " 19  YearBuilt      1460 non-null   int64  \n",
      " 20  YearRemodAdd   1460 non-null   int64  \n",
      " 21  RoofStyle      1460 non-null   object \n",
      " 22  RoofMatl       1460 non-null   object \n",
      " 23  Exterior1st    1460 non-null   object \n",
      " 24  Exterior2nd    1460 non-null   object \n",
      " 25  MasVnrType     588 non-null    object \n",
      " 26  MasVnrArea     1452 non-null   float64\n",
      " 27  ExterQual      1460 non-null   object \n",
      " 28  ExterCond      1460 non-null   object \n",
      " 29  Foundation     1460 non-null   object \n",
      " 30  BsmtQual       1423 non-null   object \n",
      " 31  BsmtCond       1423 non-null   object \n",
      " 32  BsmtExposure   1422 non-null   object \n",
      " 33  BsmtFinType1   1423 non-null   object \n",
      " 34  BsmtFinSF1     1460 non-null   int64  \n",
      " 35  BsmtFinType2   1422 non-null   object \n",
      " 36  BsmtFinSF2     1460 non-null   int64  \n",
      " 37  BsmtUnfSF      1460 non-null   int64  \n",
      " 38  TotalBsmtSF    1460 non-null   int64  \n",
      " 39  Heating        1460 non-null   object \n",
      " 40  HeatingQC      1460 non-null   object \n",
      " 41  CentralAir     1460 non-null   object \n",
      " 42  Electrical     1459 non-null   object \n",
      " 43  1stFlrSF       1460 non-null   int64  \n",
      " 44  2ndFlrSF       1460 non-null   int64  \n",
      " 45  LowQualFinSF   1460 non-null   int64  \n",
      " 46  GrLivArea      1460 non-null   int64  \n",
      " 47  BsmtFullBath   1460 non-null   int64  \n",
      " 48  BsmtHalfBath   1460 non-null   int64  \n",
      " 49  FullBath       1460 non-null   int64  \n",
      " 50  HalfBath       1460 non-null   int64  \n",
      " 51  BedroomAbvGr   1460 non-null   int64  \n",
      " 52  KitchenAbvGr   1460 non-null   int64  \n",
      " 53  KitchenQual    1460 non-null   object \n",
      " 54  TotRmsAbvGrd   1460 non-null   int64  \n",
      " 55  Functional     1460 non-null   object \n",
      " 56  Fireplaces     1460 non-null   int64  \n",
      " 57  FireplaceQu    770 non-null    object \n",
      " 58  GarageType     1379 non-null   object \n",
      " 59  GarageYrBlt    1379 non-null   float64\n",
      " 60  GarageFinish   1379 non-null   object \n",
      " 61  GarageCars     1460 non-null   int64  \n",
      " 62  GarageArea     1460 non-null   int64  \n",
      " 63  GarageQual     1379 non-null   object \n",
      " 64  GarageCond     1379 non-null   object \n",
      " 65  PavedDrive     1460 non-null   object \n",
      " 66  WoodDeckSF     1460 non-null   int64  \n",
      " 67  OpenPorchSF    1460 non-null   int64  \n",
      " 68  EnclosedPorch  1460 non-null   int64  \n",
      " 69  3SsnPorch      1460 non-null   int64  \n",
      " 70  ScreenPorch    1460 non-null   int64  \n",
      " 71  PoolArea       1460 non-null   int64  \n",
      " 72  PoolQC         7 non-null      object \n",
      " 73  Fence          281 non-null    object \n",
      " 74  MiscFeature    54 non-null     object \n",
      " 75  MiscVal        1460 non-null   int64  \n",
      " 76  MoSold         1460 non-null   int64  \n",
      " 77  YrSold         1460 non-null   int64  \n",
      " 78  SaleType       1460 non-null   object \n",
      " 79  SaleCondition  1460 non-null   object \n",
      " 80  SalePrice      1460 non-null   int64  \n",
      "dtypes: float64(3), int64(35), object(43)\n",
      "memory usage: 924.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fill Missing Values\n",
    "\n",
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Alley'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['GarageYrBlt'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 76)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Id'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "Street           0\n",
       "                ..\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "Length: 75, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19fc9271f28>"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAAE/CAYAAABxUrkUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJztnXe0JUW1h789MxIEBkFAkKgIiCJIFEVJJlSQJCKIDgZMKKA+8Yk+SSqKiagYkCSiIIKgkpMESSM5SkYBI8IIKAzs98euntP33M733pke/H1r9bqn+1R11enbvbtq1w7m7gghhJjzTJrTHRBCCBFIIAshRE+QQBZCiJ4ggSyEED1BAlkIIXqCBLIQQvQECWQhhOgJEshCCNETJJCFEKInTGlX/Ha59QkhRGtWtialNEIWQoie0HKELEQ98y+394j9J+7bt1MZIf7bsHbBhaSyEEKI9khlIYQQcxUSyEII0RMkkIUQoidIIAshRE+QQBZCiJ4ggSyEED1BAlkIIXqCBLIQQvQECWQhhOgJEshCCNETJJCFEKInSCALIURPkEAWQoieIIEshBA9QQJZCCF6ggSyEEL0BAlkIYToCRLIQgjREySQhRCiJ0ggCyFET5BAFkKIniCBLIQQPUECWQgheoIEshBC9AQJZCGE6AkSyEII0RMkkIUQoidIIAshRE+QQBZCiJ4ggSyEED1BAlkIIXqCBLIQQvQECWQhhOgJEshCCNETpszpDohnH/Mvt/eI/Sfu27dTGSH+2zB3b1H89jaFhRBCALCyNSkllYUQQvQECWQhhOgJEshCCNETJJCFEKInSCALIURPkEAWQoieIIEshBA9QQJZCCF6ggSyEEL0BAlkIYToCRLIQgjREySQhRCiJ0ggCyFET5BAFkKIniCBLIQQPUECWQgheoIEshBC9AQJZCGE6AkSyEII0RMkkIUQoidIIAshRE+QQBZCiJ4ggSyEED1BAlkIIXqCBLIQQvQECWQhhOgJEshCCNETJJCFEKInSCALIURPkEAWQoieIIEshBA9QQJZCCF6ggSyEEL0BAlkIYToCRLIQgjREySQhRCiJ0ggCyFET5BAFkKIniCBLIQQPUECWQgheoIEshBC9AQJZCGE6AkSyEII0RMkkIUQoidIIAshRE+QQBZCiJ4ggSyEED1BAlkIIXqCBLIQQvQECWQhhOgJEshCCNETJJCFEKInSCALIURPkEAWQoieIIEshBA9QQJZCCF6ggSyEEL0BAlkIYToCRLIQgjREySQhRCiJ0ggCyFET5BAFkKIniCBLIQQPUECWQgheoIEshBC9AQJZCGE6AkSyEII0RMkkIUQoidIIAshRE+YMqc7IJ59zL/c3iP2n7hv305lhPhvw9y9RfHb2xQWQggBwMrWpJRGyGLc0QhZiG5ohCyEEBNOsxGyFvWEEKInSCALIURPkEAWQoieIIEshBA9QQJZCCF6ggSyEEL0BAlkIYToCRLIQgjREySQhRCiJ0ggCyFET5BAFkKIniCBLIQQPUECWQgheoIEshBC9AQJZCGE6AkSyEII0RMkkIUQoidIIAshRE+QQBZCiJ4ggSyEED1BWafFuKOs00J0Q1mnhRBiwlHWaSGEmKuQQBZCiJ4ggSyEED1BAlkIIXqCBLIQQvQECWQhhOgJEshCCNETJJCFEKInSCALIURPkEAWQoieIIEshBA9QcGFxLij4EJCdEPBhYQQYsJRcCEhhJirkEAWQoieIB2yGHekQxaiG9IhCyHEhCMdshBCzFVIIAshRE+QQBZCiJ4ggSyEED1BAlkIIXqCBLIQQvQECWQhhOgJEshCCNETJJCFEKInSCALIURPkEAWQoieIIEshBA9QQJZCCF6ggSyEEL0BAlkIYToCRLIQgjREySQhRCiJ0ggCyFET5BAFkKIniCBLIQQPUECWQgheoIEshBC9AQJZCGE6AlT5nQHxLOP+Zfbe8T+E/ft26mMEP9tmLu3KH57m8JCCCEAWNmalJLKQggheoIEshBC9AQJZCGE6AkSyEII0RMkkIUQoidIIAshRE+QHbIYd2SHLEQ3ZIcshBATjuyQhRBirkICWQgheoIEshBC9AQJZCGE6AkSyEII0RMkkIUQoidIIAshRE+QQBZCiJ4ggSyEED1BAlkIIXqCBLIQQvQECWQhhOgJEshCCNETJJCFEKInSCALIURPkEAWQoieIIEshBA9QQJZCCF6ggSyEEL0BAlkIYToCRLIQgjREySQhRCiJ0ggCyFET5BAFkKIniCBLIQQPUECWQgheoIEshBC9AQJZCGE6AkSyEII0RMkkIUQoidIIAshRE+QQBZCiJ4ggSyEEH3B3VtvwIdmR51na1vq39zTVt/7p2sxd12L2vN2/NFXz446z9a21L+5p62+90/XYu66FnWbVBZCCNETJJCFEKIndBXI359NdZ6tbal/c09bfe/f7Gyr7/2bnW117V8llvQhQggh5jBSWQghRE+QQBZCiJ4wZU534NmMmU2t+t7dH51dfflvxMwmAeu7+2Vzui9CNKGxDtnMNgCudffHzGwnYC3gYHe/d1w7FA/R9e6+Woe6ywMrufu5ZjY/MMXdZ4xn/1r2537AAQNeCMxInxcE/uTuyzU4x+7ufnDdsXHq79LA8uRe1O7+2wb1Gl93M1sAWGz4vjGzl7v7TQXlz3D3t6TPe7r7gS1/0+/c/dUNy67v7pe3Of/chJmtCPzR3f9jZhsDqwPHuvs/a+p1ui9mF236Z2ZrVZ3L3X/foL153f0/bfvZhDYC+XpgDeKfeBxwJLCNu29UUWdx4LPAy4D5suPuvmlNW8cDn3P3+xp1LursAnwIWNTdVzSzlYAj3P31BWVfAfwAWBo4A/isuz+cvrvS3dcrqDODEK6jvoqf5KWjYTP7DnCmu5+W9rcANnT3zzT4Xb9397WGjl3j7mtW1Gl93c3sa8D2wM3A04Mq/vaa/rW57tsChwF/J67ltOwBKPqdw7+1rExN//YFrgd+4TU3e/78bQR5rv4GwD4MhEN2b7y4os68wLbACowUKPuVlL+B6vtw9Yq2rgXWSW2dBZwGrOLub62o0/i+6NI3Mzva3XdOn6e5+zFlfRlr/1L5CypO5zXPyHqE3FvY3ZczszWAD7r7J9r0uYo2KouZ7u5mtiUxMj7SzKbV1Dke+BnwNuAjwDTgrw3aWgq4ycyuBB7LDtYIh12B9YArUtk/mNkSJWW/Szw4lwMfBC4xs7e7+53Ac4oquPtCDfpdxnru/rHcuU43s72rKpjZDsCOwIvM7LTcV1MJgVZFl+u+FfFwtn3zt7nu/wes4+5/MrPXACeY2WfSi8pK6ozVDOhTwALATDP7N9Uv0Hwf5iv4vo4jgU8C0xkIhzp+CTyS6jS59pt36FfGM+4+08y2Bg5y90PN7JqaOm3uiy59WyP3eXeglUCm5X3r7pu0PH+eQ4jfeGo613VmNpbzjaKNQJ5hZp8DdgI2NLPJlAivHM9Pgnt3d78IuMjMLmrQ1r4t+pXxH3d/0iyeKTObQvnDvKC7n5k+f8PMpgNnmtl7KuqMIAmd/OizajT/DzP7X+DH6fw7AQ/XNHEZ8CCwGPDN3PEZxIivii7X/S7i/9lWILe57pPc/U8A7n6ZmW0K/MrMlq2o82Iz+wUhLLPPs3D3bao61/JFOsnMFiEWu7PPs4S0u/+jpv4j7n5Gi/YAlnH3zZoWHqOK8Kn0op8GbJGO1T3Dje+Ljn0b6wu3632Lma3G6FnksRVVJrn7vdm9nmj64m1EG4G8PTFi+4C7P2RmywFfr6nzVPr7oJm9DXgAWKauoSRE2nKRme0FzG9mbwQ+BpxeUtbMbGF3fyS1d0GaTp8MLFrViJm9nRCQLwT+QkxPbwFeXlFtR+Ilkz2svwV2qGon3dz3mtkbgCfc/RkzWxl4KXBDVV26XffHgWvN7DxyN7e771ZTr811f8zMXuTud6dz/ynpMn9JPBhFbJv7fFhNX2ZhZi9191vLdIYlusKFiZFq9sTlyzhQqHrItXGBmX0d+AUjr2GVXvIyM3uFu9f9T4fbXB84FFgVmAeYDDxWpToD3kfMmL7s7neb2YuIQULR+Q8lfnPr+6Jl35Yxs0OIa559nkVZO2PpX6q/N7Axcd/9BngLcAlQJZDvT2oLTwPSTwC3V7XTljY65AWAf7v70znBcIa7P1VRZ3PgYmBZ4h80Fdg306VW1Mvra+ch3oCVN5vFYuAHgDcR/9yzgB8W6Q3NbEfgruEFnPSS+T9336WineuATYFz3X3NNGXZwd0/VPWbupJG768DFiFULFcDj7v7uyvqtL7uZeqnOp1ey+u+FjDD3f8wdHwe4hrWTlfTCHxV4AF3L1XdmNn33f1DJTrDSl1hW7roJXP61inASsRI7z800AWn+lcD7wJOIvTC7wVe4u6fr6k3P7Ccu99WU65SHVn1v2rTt67tjKV/qf4NhLrkGndfw8xeQNy3W1TUWYJQW7yB+D+dA3zc3f9W1VYrvHl0o+nAc4mFsPuBU4Djm9Yfy0boib7SoNw8xKLjK4B5JqgvV6e/1xFTGIArS8qeQoyWCreG7f0+/f0EsGf6fM0E/bZ5gNXS9pwG5ScDP+7Y1jLAJunzvMACJeUOB16ePk8FbiRmJA8C7+zYduFvI2Y7C+f2NwEOJvTCtfcT8OImx3JtlW4t7sPrc8cuq6mzBXAbcHfafyVwWovrtgiw+kT0raAda1h2AWDy0D353Ab1rkx/p6f7yoCbutxP47m1cQwxd38c2AY41N23pnqajpmtbGbnmdmNaX91M/tCizYBcPdTiVFpVVtvA+4k3mCHAXeY2Vsa9O8HZna2mZ2fbTXd+aeZLUioHY43s4OBmSVlDyMEyh+BZwjrlONS+coRyshu2quBdwO/TscqVU1drntSHfwh9fc7wO1mtmFVHXd/Glg8jXAbY2bvJ1b4f5gOLU+oLYrY2AfmcO8jZjarAmsD/9uiTTOzTc3sh8T/o4gTiQccM3slMcK7jxBc32nQzM8Ljp1UVNDd7/VQS30p+5w/1qCtx9N1v9bMDjSzT2Z9r2AfYgH2n6kP1wIvqqpgZhea2VQzW5QYhBxlZt8ar76Z2RfN7KXp87zp+bsT+HNS19VxHjB/bn9+4NwG9a42s+cR1lbTCfXUlVUVzGwFMzvFzB5K28lmtkKDtprT4q11DfBqYtqcjVhuqKlzEXEDXJM7dmODtrbJbe8Avgr8rqbOrcS0KNtfEbi1ps51wEdTH9fOtiZvZEIoTgN2IxbRqur8dmjfho9V1N2QEF6fTfsvBg4Z7+tO3JSr5PZXBqY36N/3gKsIC4pPZVtNnWuJ0Xi+f4X30lCZXwE7F31X0dariFHufcC/0v9skZKy+RHdN4AD0+dJ+e8K6r2U0HXfOXTv7kzNqIs0A8rtTwZubvC7lieEz1Rgb+Bb+fu/pM4VBde09HflyxLWSPs2rNO4b8BNDFSnHwIuSNdgVUpmnsP3UpNjNedYgWYj/98Rg4J50rYzNXKp7dZmUW934HPAKe5+k5m9OF28Kp7r7lcOrUqWjSbz5PU4M4F7gC1r6vzF3e/I7d9FLLpVMdPdv9ugP7Nw98dyu01NdJYwsxXc/Z60vxyweMP2fkuMxrP9u4iXQBVdrvtzPKdXdPfbzaxuBR5iwfABQmg1tWj4t4+0zJhcUfYRM9sstfFaYJdcnfnLKpnZl4F3EoL4BGA/Yipd9T/LX7BNifsdjwXVqt+zCmEO9TxG3rszsv4W9O9zQLYYmnlsGvAkDSKJ+cCi4QmaWyXdmNZPJlvYi+9GWPNUMcXMliKuZaV+umPfnvQk7YA3Az/1mHndktYL6njMzNbygT372qndQszsZsIs9KceZq7knss6Jrn7Ubn9o83sow3rNqKxQO4oGP5m4R0Uw0KzdxC6v7q23te0XzluMrPfENNOB7YDrjKzbdI5f1FQ53Qz+xih682v0JaaN3VZcAQ+DVxsZpnAW4kYmXciW7CqKNLlul9tZkcSKhUIFcn0ur64excTxUvNbE9gvrQouisx+i3iI4TqZ0ng0+6e/Y43AGeW1IEYbd1G2Jz/yt3/bWZ1K9jnm9mJwEOEHvN8gCSQniyr5O6/BH5pZq9299/VtJHVOQA4wMwOcPfPNamTx8zupsBkzCucUIh1iM8T9/pPiAXYOvXIfqncJe5+VRqI/aGqQsu+/cfC/OzPhM7+f3LfPbembxADxZPM7IG0vxRhEVbGDsSC49lm9jfiZX2iuz9QUSfjfDP7H+CnxO/bnpAhU2F8QiG0sbJYHNiT0Bs39f56MfG2fw1hd3s38G6vsVc0s2UI64ANiB9+CbC7u5fp/jCzo8q+i276+wvq3F1StuqmHj7HVoTjx1415eZnYNp1MzEyKLVhTDq7wq+A69y91Iyty3W38BjblRiFGvHy/Y7XGNwnC4Oih6/qvphMCMy8Zcb33P2ZijqjhJ1VuDqnNt5EPICbErO5NwDLunvhbMFiGLw9IfxP8mQzbWZrAku4+1ll/Uvl5iMsToafkVH33lC9RYiXdL5OpWuymT0/tzsfMQBZ1N2/WFVvdtCmb2b2KmKmuTjhrLJ/Ov5W4D3uXmoeailWCaEyW4W4l271CsuvofrrE//vbYE7gBPc/QcV5e+vOJ17g1AItbTQs5xN3Gy3ABsBPwK+VlF+EmkVnNC7LtSirXMIXc2UtO0MnDOeuprx3IDLW5TdEDgCeKim3NOE2uXu3JbtPzkR173jb187t21A6AsPbFDvOcQLalUi9kVd+d8XHKvVcady8xFrEScTI7GfVJSdTJg0drkWJwH7E7rkaemZObimzgcJu/KHiZfGE8D5Hdu/pOb7c4Dn5fYXAc4qKZtZ9BxKLJSP2Cagb/MVHFu0wXnHrMMl7JGvIZycxnSusW5tdMitvL889G4fJ6YDj5WVK2FxH62r2aOqQsdR9XMI1UFmTXAhMVKrsq3Oe4ZNIuwsK6cZSa+1I/EmXpxQ9dRZm9wFvN4LPACr3tRtr7uZneju77SSOAReYw/r7sNqjUur7ovU5mbECP4+Bg4Bu7j72QVl1yMWkxc3s7yKbCr1XmZZH/9NWED83MwWIhbcyso+bWaPW85xqAUvcfftzGxLdz/GzDK1QBW7A+sSL/VNksVBrRrIRjq8ZPdhnQ5/Mc8FEnL3h63czf2W9Pfqur6MU99OTtdtZjrHUoQaa+2aemdbOHXVxioZ6uO6xOxpW2KN6vuUWMTk6lxODERP8AkKWtZGIHfx/jon6Vx+xsiYFHUuqH+ziCh3Qtrfgfr4DUcRerHt0v5O6dgbK+p8l3ioM5Om96RjH6yo03jB0SKwzfbEqOwE4sG70t2PrDh/xkHECKbIJbsu4lmb6757+tspRsKQamUS8QAtWVPtIOAN7n57OsfKhNnbqgVlFyDcx6cwciF0BoP/dVG/PlXb+XL+DdxgZucw8vrVrZlkz8g/k170IWIFv7ItD/02FlHEbjWzVRr0Me9On92H76yp84yZLZe95C2i9BUKMXc/Pf1tG1uia99OJV6Y2xIOTacxUp9cRhar5GkzewKqg32Z2VeIZ/JhQhe8QdWgbYidiZn7dWZ2GXCUu5/XsG4j2uiQu3h/ddLRWnjMHUaMjJxYCd6taLSYq3Otu7+y7tjQ99e5+xp1x7piZn8nzHq+BfzGw7Lgrrrfn6vfKZ5vl+tuZl9z98/WHStpy4kHYSahUtnP3S+pqPNbd9+w7tjQ9y/2WEhuhNUEb/KKxUjr7rX4QUItsjoxGFiQ8Pz8XkWdU4iHfA9C1/0wYfFSGoGtK7mZSTaD2RD4kFfoxtPL8n8YHY1u3Dwdc23tCmyW2vpw2/u+YRt7EyPczi7PaX3i7YSMepIYNR/qNWFMG527xSh/XDCzedy9dMU6ldnA3S+tOzb0/bnA0YwcVb/PC8JA5ur8HtjOk/lLWgz7uZeEeLSIdLcng5Hc1SThUzTFTSqRzVJfNiR0eJsBS3vFAtbQOVqHgSw5T+V1t+Iwn9fXqSw69uU7xOwqbxFzB8mKp+gln6bB/8towdAqHGefMbONiHgaZ9b8r9YkLHeyReKrCb39HWY2xUsWLVPdxYiFMCP0r5VuvxahAo5gKIJdgaqqU9+GZjJGzFJvIHS6uHudEwoW8WVmqR3dvcxiJ19nV8LT+J9pfxHCfb/SAcjMXka8QLcgrHCOJxbCtx+Pe7FWINsgiEchDaZx2er1JoQedQt3f0FN+SLhUBkLt2RUvbtXWxa8nhjJ3EXcDMsTQnyUfbWFedz7CYGc6dXWIcyGDgb2qhpZm9lzibfqDoSzwtnu/t6y8rl6jeP5FtStve4WdpQfIxxO7sx9tRBwqbvvVNPGdoQAmWHhDbgW4X1WGlDHzI4r+44YyY+6LmZ2K2G3ewPh9ZgVvnO47FC9xpYPZXr0XJ2qWMMbAQ+7+/Vm9k5CQNwBfNcbhIZM98fLgHvdvTRUaprSfw34CnEfGqEm2o1YD/lSzSCklUWHmU139zo9bue+jWUmk+p/lVAFHp8O7UAs9lZ6cZbMqOvijF9BLLr+iLDCeSL33WleEzu8EV6/Ajmtaqup29hLKpV/NfF2vZ+c1xfh8nldXV+7bEQchdWJQCPzVpS7hYJVX+D56Z/00RZtPo+Imtek7AxCAD0FPJr2Hx2v606MyFYgZhbL57baFe5U//r097WESmtLkkdY1e/v8H+6tOP/t7HlAx3jSxDu5hcT5lc/JvShHyEihxXGeyFezvcQLrtvJVQ9lxN652lV1xtYoeD4CoTuuzTmCx0sOtKz9zHCvnfRbBvvvnXdUpuTcvuTqfEkzNWzoXqFXpVEIg6Alce7/8NbkxHyfITp1F+Hji9BCIZ/F9QZ9pI6hfCSqvOb34gwQfkIMU3KmAGc7kNRwlKd1iN4M9vU3c+3kRYT+TqjnEjM7BaPGApF/b7V3V9acLxy9uDuh1R935au133oHG3iPM8aVZjZAYT7808ajDTuJOIGHOUFlhUldd5ErIify0gnnrrIgVn/rnf31ZMa6SwvjsDWKYWTmd3s7i9Lz8qfCJvlp9MM5Xp3f0VBnesIVc3ChHBc3d3vStf/vKI6+bZKvrvN3UsXBNMMILPoeKUliw53L3WkaLMeMca+nUOoD/MqhJ+6+5vL6qRy1xPxTv6R9hcl1BZ10fK+TrwojiDkx0eA+9390wVlW2eq6UoTK4tDCI+oYSH1RmJUVORx1sVLCh+Y0x3tzYNdtzbLIeyoz2ekxcSsbjD6twI8amZruPt1+YMWaVzKzKMyq4CViNgSWZzgzRksrNTSQkfW6bqnNrYgFh/bxHkG+JOZfY9wuviahYNJXdCqlQg32V3M7HDi5XGMV6sf3k3MZBZkoLJwYjW+ijaWD98hVC5tdff/hjCvM7N7PTn8uLubWZkJ5TM+sDK529OCpbv/xcyq3NyfspylRIaFxUSdaqS1RUebl/kY+7a4NzfJy3MAcI2Fg5IRz0kTz8fPEs/LR1O9sxkEu5pzNBjalwY6oXyIP5kI+HwsEVnrOMJ1t9YBIJsaEKvBZxOC83xaGMvTMHwf8KImx9Lx1wL3ElO4LQihui8x7XxtTTtnAVNz+1OJWNJNfstXiYhW70/bOcBXx/u6E4GWns8gmMwmwPcb1HsuYde7UtpfCnhTi//VxsSockb6neuVlKsNSlVS74PpftiQQXyTD5eUvaboc4M2/kio1j6d+5zt319xvRdJ1zz7nKkEStVzRCja2wkTrFcQoVLfR7yIt6rp5ymEumwfYgH1l4T1T1HZTdPfbYq2CejbdCJOc7a/PAXOQCV1lyJUQFsCS3a4RxalIrgQEQT/+oLtBhqoR9psTVQWVVP10u9yZeYjhNcOhFA7z913rKnTeGXXzL5IOEHcmkZnZxDhEmcCO7p7aSi+ksXD0kUMM1uS0Ke9nHir3gQc7u4P1fyeW4l/+JNpf17ioRul5iioez3wSk9WGRYmN9d4/ZSs1XU3s6vdfZ107df0cDApTPhaUHcNIog+wMU+NIsoKP88YsT7XkKf+SNCWKxNmCSNGpVZxNk40GsCqw/VmQS8w91PbFj+OuIFMYkYBGwM9SmcuixM2UhzwYIqlSaKaxDCPn8ffqPuug+do9Kiw8z2dfe9rTgkgXuJO3hB324EvtngnmhlkpdGz3sBLyEE4wHeIpaEmV1ICPEpRPTBvwIXufso+3Uzu4nQ8xfiY0urNepkdW+PiygYtRC6qMoQkgyNNomR4fsatNnIJTaVbR2+jzGES+yyAV8kzHi+kLbpwBca1r2e3CIK8TavCgU5y3V66LpPq2nnXEIdcCihQjiYBkHFCceSG4kgNPsRD8cnaur8gZhdLF/w3V4ldW4gpr03EQth19BgBFV3jw6VvYfR7urZdtc43xOvTX9HuQxPwP23aNU2ge0u2LL8YsQgYgvCq7Cq7JnAlwnV16HA0S3bahxWlAlKCFG0NRkhr0fYix7NIPpXlpblXe5+RUXdViPQXJl9iKllbRQ2G5km/mTCnOx7Ze2n41sS06u3M1IHOYNYSBhlkF5hEtU05c66xFvfiVHkVVXlc/V2INQWI3Rk7v7TijqVThYldRYgdKFGjF4XJiwEKj0k0wj+1Z7ctNN5fld0PczsK+6+l5lN8oZ22Lm6KxYd93qzt/8jrAnaeou26Vvl4qwXLyxPd/e1uy4YWQuHjS6j8bSOs3P6PM1beOxZJFQ4khDIy6VR84c9l3m9oE52373Y3fezMGNd0t0Lg8bbkNla2+uYnuc3EYGNPu8Rya7Q7t7MDnP3jzc991ioXdTziKu7HhEJbOd0+EbgVe5eGG84rd6+HFjYRloyTKVZevVp6e9n8l2hOMlk6/B93iFcImNLvw4hFB6HWYkZG+HuJ6Tp1brEA/VZr1GR0MFl3bvFeSb1KR+17mmKH3wIp5i92grj3Hkf8PB2fC2xwFeYoHOIbGq9a+5Y4b1kJQlRZ1Uqt62uDVNawFNJHTAqsWdqq86+/yRCrfdDajIfe7uFuYy8Tf3utLsnDiJGrqel9q+zmuwzxILqM4S34n7E4Ohk4r4vwmxkVvDJ+f0GL9zGYUUzYWyRd+8rwAvd/S0WTiKv9mahEBoYEv5cAAAfoElEQVTRKJZFErx7W6RlWZW4cFVugq0Ddg+11+YG2oMIHLM48G1PGY0twvddU1TBzPZ09wOBHdMIdLj9UQ+Dj0FPZBHsJ4u7bMCJZna4V3gF2eisyZm//QvN7IUVwgHaCaF8fOdReHWcZwjHmissXICNWFgpu0EnDz1Ew21VPUSnAuumkfKxRDqrn1D/olzVh0wzk369iCwGw3zELPC61NfVgSsIXXxRv7vEe9icsEzZlG4CvXVyBYA0QHotg5naqSVFG1nnlOHu99vIoP6VLw1igLeWmWUeeg9bdWqw4QzhMMgSXjZ4y/fvJHLBhDysXLYtrwGEluAoBoH6bycGPbNXIMMsAfc9Qu9qwIvM7MPufsZw2Y4j0HxbjaOwediNjlocc/ffEOm9i2gdyapCcFUGM0l8iNDD/yud6yuEJ2GVm+anUr1vFnznVOQYbPNCc/eFUp/2I0zCjmOgtqjNAOLu30oj+ExYvc/dC1+ExP9p+CGadSqqH6Jn3P2pJFAOcvdDsoe3hstIpmw1x3D3TQDM7KfEgtINaX81KgLdmNnpVL/URnlwebgs/zQtjDdejMvRJbnCd4hFsCy8wEfM7I3uvmtB8WzkbhSM4mtG8Peb2WsAT0J1NwbPXBlPpQVrT31dnJxH5jDuvkLN+QrJBmNW4r9Q87sWc/cTLbK94O4zzazuRdOKNtHevkVkCb4DZun0fk1YNZRxfxo5NQ6JmWgchc1qonp5gS+8d4hklQmujhgDe1jS58qcQB4p7CcRi3+lMTxKG4wHYgVG6hePrajyZnd/VW7/uxauonWR5WY1STxAVb/rZq9wGKlhpoWb9nsI/T9UhN+0sIhZmkiRtGauX1Opz0Tx0kwYA7j7jRZJT8v4Rl3nC/o3SyBYQXqoBiqLNmq9jI2A1TwtHJnZMcRiaRH587a19f8IsSi8NDGzO5uRs7UiDiFeLktYODi9g/oQtQCY2dKEmVz+Xi9zB+8cVpRIF/V8Bv+39Sn3QehEG4HcJWfdUbQPiQmwro+MC3G+hUlSEZmgXIXQN2WLdFuQSzmVp8uIpuAcbTzajgMuT4uOAFvTQCfnYXr2DcKlvDEWsSJWJMx5sje4E1P9Mp42s3czSE+zA/XTzMzscDtC32dEVuKT3L1J5uQ2vJ9Q+xzo4dH2IgYjvSLeTKx5LEMMJjJmEOZSVdxikZ36x8S12ImKEZ6HQ1NbugiEfJtd9MK3EfkcM/XbsoQVT9H5R9yfZraAN4xrnkb/727TMXc/3symA68n7qOt3L1uVI2ZfY0Ip3kzI+/1wme/y2Asx6cI+bKimV1KqEnf0eE8pTSxssgW5d5IvIXyEbpu8wJXw1zdovCWlSExU5lWUdhSmbOBbT0FjrYIRH6Su29WUHaj9HEbInZvtji0A3CPV6RjsvCa+yZDHm3uXunRZmFl8TqYlXG6qZVF6+BCZnYL8LKm5VOdFYhRTTabuRTYw2sSQKa21sz0tBapqn7vBfbpZrazux/dtE/jgZlt6+4n15ccUWc+RqrMfksECRoVJmCoXmbNMAJvkRKsRR+fSwiI5dJsaiUia3hppDOLxAHrMkh3vy6RSfnx1M9RAxHrZjFRZHXyCOHG/8uSOq9goHq8xd1vLDv/UL3bCBv/2gBOqXylZ2fdYMwi8WqWLuq2IjXqWGgyQs4vyv2ZmPZAGFIvUlP3r9Y+0DzEdOkCMxsRha2mznKMTET5JCUustmIxsz295HmYaebWWUuMyJQzfpEmp81LZJ0lub9ynEbYfEwJbW9ursXjk6GaBWAO3Ej8aKpTSibkQRvXWbvIu4hZgqZsJqXkVHj8m0cDbNMtj7D6GlmkcnWikTYzYeJ1fvvMYiktkvN4ibArywyLa8w1NZ+ZRWS4P122tqwTu7zrFxyVRWSrvSzRKS3RrkqE0cR+vjXpP0/EotUVaEnu+Tb62IxMR8hXLNFs20J+/EPmNkm7j4r+4+ZLUx4DGajdQNeYWb3AVt6vbPHXYTqqpFAJmab9xMy6QpqVIepj2UZZlY2M7w4gXInmpi91QnCKt5PhMT8NswKiVl7Pnc/L3vjw6zEhXUX/DjgyqSzdkItUDVFh0gLNCvweZoGL15T5yl3/7uZTbKwp70gTZtKsfDk+hDhYJCNoJzBCKyUjrrrxYCbzexKRi74lL79k2DYhdGCqzJBZzr/TRbBYZyYSV2SjZJKdKGZydYPqFeLHE08PFOJB2hP4gX4OmKNYf2a+r8kRmfTafjQmtkGhHvx8AujbuV+eLBxkJldQrUgPJ5YqX8boXudRgx26ljR3be3ZCXk7k9YkTJ6ZP8usogrsZK7n5tmM1O8Jh2Rt7eYeAnhep2lY/ouoUd+I6N11vsT6ptNfaQ36gGE48cnatp6HLjWzM5j5L1epoNfMvVjByIs7a8J79CbKtooinkzqymKY990oo2VxVEUT8dKH9ikVx0hBCxy4x1U0sZOhBrluCSAr0/HdzGzx9z9JxVtfdnMzqTZan/GJ4EL00gcUqaCmjr/NLMFiWns8Wb2F8JNu4odCYP3pm/xWaSH7N2E1+P+ZrYssJSXGMwn9mnbDiG4LiY89tqsHJ+StowLG9RpY7K1kCfzQIu8e9ls6wyLCHN1LFOktqrhSOLeGOG6X4d1yyXXKldljieTQM0WmFak5oVjZrsQA4NFiTWGZYgXY2n8ZLpZTCxNzOqyBa8FCNvdp81suI9vIFQO+RjXT5tZFvu6jtOoDzA1C4/AT2cCZ1qEMNiBkAH7ufuhJXXGMihtRZtFvfxUaD5iBPpAhzY/RYlAJnzgi0aNPyM81UoFcuJaUjAdACuIPJXH3c9MI/FMd9VkJL4l4eTxSQYebaXT38RNxIPZWiAz0mB+fyK+8eEUGMyb2WFERuUui0zP9Zp0TSWc4UMOQma2ilfHnGhjspU3fRpe0W7iYHKZmb0ibzXRgEe8wJyzAcO55O6mPpdcl1yVAHsTgmVZMzue0P3vXFNnVyLq4BUA7v4Hq4+o1sVi4kBi1HohzPIu/YqFF+dwbJknvSDDiYdJWe3zkl+cs7BxX7ZOFZgE8dsIYbwCYeHRaJSb/kfDyQ7qnv/GdE7hZGGSdW4DXddwvfvdfdmS70pTBlV9l77/BHGT/pmBt5hX1Un1GpuHpanUWe7+hqpzFtRbm3BsuJ6RAqg0+3Gu7u89Gcz7wEW8MO+fme0OvIuIfvUzYip2bcM+fomIXVFmu11W7zYib9yJaf/TRPD9wri4qczdBYe9SCVgZo8DtxL/z1XSZ9L+yu6+QE3/biam0HcT1772vrDIQjGZeEjz/686fXVrrEOuylzd5zNIx3S516djusLdX2WDGNFTiAXYiUjTtRQh/I2IKVM4eLMIvLUDo3W5Bvy4aHF4qP6FNAwSlMofQ0ShO4MIk9Bo8TDVPYIwmdyE8JB8B/HbPtD0HLVtjEEgrwL82t1f0rLefe6+XMl3twDr+JB5jYXFxFVeER3NzO4gvH2aLBpmdQrNwyr0T9kq7Xu8RYp4M7uRiGg2nH6oNmOthS3wa4jfv1bS9Z7t1QHglycE87uIN/kJxM1XmtjRwvFlAUIAZXbSdYuH2YP3fWJR7wXEdPbTnpxgxoqVxLDI8PpYFsuX1Cv1vLSIrVtQpXjwYWOI+zAWrJ39LWZ2IOFh+15CN/sxwjb88xV1WltMpHqNUkUlgVplgrpJ2XepfvZy+SAxOt67ZmD3DINwAvl2a+93GyQ5yP4uSFg/vamqj21oo0POPNUs/X2IWB2uKjvqK2D+imaOJFKBf9STuZWFOdbh1Lsn3k97I+11aGkeRrcU8f/wBskaSygymP+/qgpJ2HyNCBi/JvEy2JsY9ZXV6eT44u4PJt3954iXzefKhLF1yNRSJ3Ab9O9ei9gXK7n7UemFtmBZeYs4LF8i0lD9K3f8LRXNtI77YGPMVWkD+9ubGBmwv8pK6H+J/II3EGslv6E+KHtji4lc3z5IXIdliMHO+oR53agXmrtvXNN+HVPSoOCdDFyaS3H3uuQJVWQ59B43sxcC/wC62IOX0lggt3lgx/Bwf8PM/kUsbGQPzb+IgOx1i0B3Ecr5XzNymlklCFubhxGrsr9uUR7gKjPbn1h8yPet1uzNOxjM2yDb9btSvYuIcJdVdQotPqpGXKneOcT1W414AH9kEW2uyNV4I1pmajGzhyl/ubu715mV7U28eFchTMWeQ9idb1BQdjdCP3oLkC20ZaPAL1Puldplmpl3DNmXeGG2YSvC7rip5chkIivLToR1S1PaWExk7M4gVdQm6SVXeP+VvZwzil7SQzQOEjQO/MoilveBDOKPjGuWkVqBnKZ8/8ym6BZ2t1sR9qeHe0W68i64+xHAEUkgm9eY5OS4L23zpK0Jrc3D3P0Yi9Xt5WoWrvJkQd43zp+KBmZvZnacu7+Hge40f2y4bGbOszmxcJPFZGjiYZV3lZ0v9Xk6FTEzEof7IEDNP5NOvjCFjrvvnf62WbVerEXZIrYG1iQFnnH3B5IKrIhdgLXd/V9pZvZzM1vB3Q+m2l61ddyHocWoPTqoOVrZ33pYLixuZvO0fGbbWExktEkVlb2clyBUc+en/U0Ii51KgezdggS1wsKp63533z/tL0i8jG6lva16JU1GyCcSN/UjFv78JxE2gq8kLABGxZfoihXEpbCc/WPVaNdr0oWXsE/bCha5575BCP0XpWuyX40Qf13Zdw0Y4QGYRjpl8aT3IixR/sdbxvt19xGjVgvzutI4Fpai0bn7qemh+086z8w0ai6q01rX6ik/Xe4cizIyhGudpc+T7u6WcgtarPSXMTlTU7j7PWa2MSGUl6daII8l7gO0GGHnVB1t7W8hBlGXpnWQvLqtahbZxmIi449pJHkqEQr2YUr+T9nL2cx+RagPH0z7SxGqykIsTPgu9LAUMUKl+Y70G6d5vclrG7KckdlM8quEDv6VxPrJuLlPNxHI8/tghXQn4Efu/k0LK4tGK/gtaB2XIiPpBvdktElKVVS0iyxinGYmZFd6SYznHPsQo8cL0zmutXAoqevbl4Cl3X1ziziq63mFG7FFRKm9iOA4mbeSER6IhVNOH0QrW9HCbvs/SaisDhzruSSSDfgjoYYo4ycMIqb9jpHR075DQTQ1xhBj18Lc6NuEWuTvxMjtdgoi/Q1xokUS1uelh/j9lE/ZHzKzV3qyTEkj5c0JHXxhFuhU7pjUx+3SiC3f7+2Ka3UmE/jTaWF/m3ggbZNoEMkPwMNG+jcMLCb2ysmDz5TU2Tp93MdigXRhwkSvihUyYZz4M5Fbs4zdCachiFnhGoQ+d01i3WUsg6BhJucGONsTuSZPBk42s/GVgV6f6uSG3OffE1HBsv1xTfCXO+/ZhENAtr8Qkfurrs4HCP3fRsRD9LWaOu8kAq0cQ3j13U3kYKuqc4UPpXWpuw6EznlHUvJKYqp5Q1WdXN0DOly/a4mX7UsIN+ZvU5LMMlfnUOJGPoTwrryEMDsqK1+aEHR4P3//FH1u8ZsWZ5B6543AERXlXwJskCv7dWJm80XCy62ozjKUJMnMzlXTx1G/qex3EkGOHk3bzNznGcCjDdpagBAU2f5kwpZ8XJ/FdO5FCIG8YbZVlJ1Eh4S06Z47i7Clnkbo6w+tuh9yn39CRJHsdG816NuNpETBhJpiw/x349lWkxHy+WZ2IrFwswhJx5OmFOOqP87ROC5Fji4eT58nIsv9BWaNZM8lAt6XcaNFbITJFk4luxEu4VUs4e4/MbPPAHjE9W3qAZaPsJepLL7g1SqaZzxUB1sTsYMPtfrYwfmp9kzChrkq7KeXfC7azxhLjN2Z7v5XC5d1c/dzLKxOyjiIFNXN3c8hsnVjZuuk70YtLHpFWNiqa5EsMN4KLD30m6ZS4sXpYwvnCpGh+w3EojeE9dLZDGJb5Pt3kLvvYSVRDr3apb6xxUQ61zNmdp3VOGUV1Pt4ul+zdZXvu/spFVWeSTLoYWLhOn8vVFlydeEEQp78jbC0uBjAzF7CHAi/uQcxTF+KSMyYeRYtSQMzk450iUvRxeNpko9UUfydeMNX8Qnid/+HeDOfRagjqngs6T4zPea6xEioCa83s22J0f9ixMi/7kXzlEWMg2kMBE9p7GCYtVg5D4NpYt2CZZlwNUKdUMRYdK2PJL3lJcCxFi7rVZ56K3iBFYu7X50W7MaTB4jf83ZGZv+YQXh0TgTzec4sz0O9Uhbn+bj0t3XcZlpYTORYiohvciUjddV1YW0vI15gziAiXRlfJK75ZOA0T7EoLCI53lVVsS0eYRnOI37X2Z6GxoSsqIu10YrWjiEW3kEbAve5e5fUM03bWZtBXIrfeo2S3oo9nvbxFP+0pM7XCf1qFh9he0L9UOpCbGZr1vWloM46hPvpy4m0QEsT4UUbncfMticWOB4HdqgZuZJ01B8hko2ekHTc27v7VyvqbEyobu4hhOqyxOJIWUzpaVV98IoFuzJd6/Cxoe8XIn7/JMKxYWFCL17onWZmd3iJ01LVd2PBzJ7j4xyOsaKtS4ns3r9P+2sDh7n7qNjZbUerQ3Wvcvd1k670VR7rEpUhdG0Q3nYEXuHSb2bvJNRKFxL33+uAz7h76WzVwr78Px7mbi8jTD1vJeTFuDgmzXYa6E9+RWQZgHhDPAicTgSE3mM89SdD7U4mYg4vl20dzlHYP0bqF7chAph/mwr9Yq7uBcQ/fX/g5S36Mg+x8PBKYJ4W9VYiRg7fIxY2j2ACdIXEyG6V3P7KwPQG9bZrcmzo+8a61tz3X2lyLPfdCUR4zuHjHwB+Nt7XL517cyKP4z9ooQ/u2Na6xPrAxWm7g/ByrbzewMkt2zmFyI25T7r/fknNekTH33MdodrL9hcnrbmUlN8buJwYJR9AqFK/mPr4+Ym45rNja3Khbsp93osYlUAstE3Uot4ngL8RHkHXEzZ/rdsiRvFFx39FRJgaPr4OcHqD8y5J6I4vTX37Qst+bUIE5WlS9lbg9emzEQGYbqqpsxKhB7+ZmL7dBdxVU2fU9W1yzdsIV+AtxOzlzwwWEA8hVsuv7NBO1QP7AuJFdiER9OebhKrnd5Qs3I3DfXsHMeOyiTj/UFvzEmqo1QgLkOcA85aULV2AbdnmRoRapnJAQeiZryL0208SYQkqX0wMLXITM6HShe/03E0mYks8CkxNx+efKLk0O7YmOuT8FOz1JJMhd59h4Rc+EexOjNYax6Uoocx2dAUfg37R3R8CDkkmPXsSb+ZReuQ0dfsuMdI/lXiTH0PcNFULUnnW8xSk2+OO+6bVZD0gPNL2Jkb9mxAxqOsCcV9tZkcy0De+m4psyF0WsuigazWzDxPql5UtMslkLESFHtrd/wy8xsKRKTPf+7W7n19WZxy4n1h1b6cH7MbvPDLozAqOk65Pkblh1QJsKcm09Xp3Xw2qVQ5DHEZ4iZ5EDHLeSwwSqjjTzM5ipPqwKtDVTA8b9cfN7M7cM/LEBMqliafBW/F0YsS6NbGi+bzcm6hypDaGN/EFJDOTMZ6nbIR8R0Wd0u/S96sS07cbiRHXx8hNtYbKXkOshC9AGI8/AnyqYd/3zH3ebui70ql6+n56+ps3Wby4ps68RGjUXxDT1E9SMuJK5dcgFg3vTX+zbRtgkZq2ntPif7gIoWI6iQgElW2F13xOboQaIYvr8alsG+c2liQcg24hbG7XStvGRPjYojpPM1ChtDKxIwLot1IXEoGHIDdSJSIJ1tXLqw+3ril7BUl1RyzOZ8cXZpzN3mbn1iSn3hKEv/hShJvs2en4JoSbaZeV27o2jyScQ2rjUlhNICN3HzULMLMTgPPd/QdDxz8AvMndt6/o2xWEyuNCIgJbaZ41y4XMTPt3ETrq2lGKpbCbw5+L9gvqXkosivyc0K39iYgHMsp9dSwLPql+64WstAC7P4NIZU0jy63GYKH3Yq/O8jDbscjr+C9GR/Xr4kVa1sY0wlZ3HUbOEGYAR/s4phNK7Z3PIA9fI4sJizRobyC85x5M285eEDJ2qN4LCHtnp8ZJy3LeoUPHFyMSOLSJf90bOoffnEgsAsKMYrxu7PSPP4XQb2VT53WIhbetPVQSw3WmAF8hPL3uI5l7EeqBzxcJpSSA89GwDsrve0XMWxsZ/3hYsI/YL6i7LjGCeh4h+BYmsjVfXlA2L/hPdvdWcQC6CFeLUKnbECP4Rjegme1KBP7J4mZsSQwQvtOmvxOJmV3t7uvUlxyXtlonb+3YTheLieWJdYJ5iJnWVCJJ7B0VdVpbWTwbaTJCHlOW1j4zpF+8ySv0i2b2bUJv+UkfZLaeSth2PuHuuxfUOW74WA539/dWtNd5hNyGKsHfsH4X4XoBsVDZWNdnZtcDr/FkzmQR4OUyn4Dg6l2xCGx/fjaLnKA2dnL3H1skAhh1vYtmkbMLM9uSSJl1eNq/ggga5IQKrsqE7TrgjT7kpFU3qn620WRRr3WW1rFiHeJSdMHdLyD01U3YnMhQMeshcPdHzeyjhCXEKIHs7u+x8KzbqsNoZg2LGBbG6HgW8xVV6Pjy7LTgk6PLQtaewG8sPCmbhko1Ri4wZ0H0+8SuwJ4WUdAaB/lvSRYcqSim87hPd81sfcIyZlVixDsZeKzkN+1JLOZlzEvouxckZpJVo90uTlrPOpoI5C5ZWsdKlol3c9pl4p1IvEjoeIQhLH0Q0vd7AK0EsruXBpOvoMvLs0rwNxEmXYTrlwld63zUhEo1sykesXiPAy43s+w6bk2L4ESzAx+7O3QTfp3aGqW+s4hEON60sZiYx93vz+1f4hGU5x9WHWUP2ltZPCtppUO2QZbWrxMhJwuztI65U2bT3X1ty6ViMbOL3L1QnzU7MLNTiXQtxw4d3wl4Z80ixxcIAfQzRi6MPFpWp2MfJzN4ea7ObHh5dlnIaqNrHVLdrEvoFo3wxrpqLH0fb8xsAyLozWPpvliLiCXSedG0oI3biABf9wwdfx9hD1+Z8qpDe1e7+zpDz+Jl7l4UM6PKO/LOor6lwcqlRJyMLYhF2+z/WxXL4llJo4whNoYsrR3pmol3ItkV+IWZvZ9YCHRi9Xl+YrRWxYfT30/njjnhgThueIcU5+PAot4+p9i5ZvamhrrWWaP8JIB7JYSH+C4x41iDmDlkdt3jOZD4JBFj+K3u/gcAi1CtO45zOxmPW8Q4uc4iJ9+DDNQmw1xhZrsUWC99mPLYFMsQYQVeSjiBXUYI6N+NR+fnNpos6nXO0tq5Ux3iUswuzGxTQrdtxEJgbaLS2UnBy/M0Iob1nyaovdYLWdYioaqZ/ZGwTS1kTi5iDWODDOFfBP7kEX1w3BZgc+28nnCl34pIELEusLm7Pzye7aS2GltMWJjInkr8XzMnnrUJXfJWHs46Ze3MQ6hEXkOo3l5NZCoqzV7+bKSJQO6cpXU8sUhzc9DsaGsisIiS9TJGLlL+ZJzbmBMvz07Zqluc/0Fi5FmoDx8vU8jxIOnRzyQ8Izck1j2udffS4PZjaOu1hPC7jFCZldrDdzz/WCwmskEL1Fgv5eosTAjhDdLf5xGWO23Sfc319NIOuQgzu8/dx3WKP7tIOuQ3EdOys4A3EwselQkeO7TTi5dnHW10rRMxwpwozGxJQnVwlbtfbGbLARsPrzuMsY189vd5iZfg04z/i/BS4F3ZIp1FtLdNSRYT7v76cWrn+4TwnkEsRF9OhPoc99H+3MDcZFbSNxOnNmxPxJR40CM56Rq0yPjdFHef5O4LpW1qbltoooSxmW2QraCb2U5m9q0kiKr4LqGbzHSt9zKIoTGqifHr7cTi7g+5+7eSMF6MSIw5bsI4tbFQ7n86j7svMEH/40KLifTSrLOYaMNyxIvlIcKj9I9Am1RjzyrmJoE8dwzli3kiLbjNtIjr+xDw4jncp/GijXDNmJlMCLcEDvbI6lxmMjYuI7GJxMzWN7MLzewXZrammd1IxDr5s5ltNqf715FF8jvu/vHc7uLj1Yi7b0bowLMQDJ8GrjKzs82sN+qo2cW4j9LGgtXEpZjN3RlPrrHIwvsjIv7AowwWPeZ2Zrq7J53jwWkha1pNnRnJMmAnYMNkrleY0cRbZs+eQxxGhKZdmIgd8hZ3vzytG5xAfYLPPtLFYqIT6eV8o5n9kwjA9Qjhg7AeEbXwv4a5Rof8bMEiD9dUT5ke5na6LGTNDl3r7MRyGTTM7BZ3XzX3XWt39D4wFouJlu3sRlhWbEDowzOTt0uJRb25N5RmBySQZxNm9i4i0tuXzWxZInzkhKXAml2MVbgmXevffS6+EW02xR2ZE3SxmGh5/m+RbI/d/cHxPPfciATybMDMDiOm5Bu6+6oWCU/Pcvd153DXxpU64WoRF+GrRIqj/Qld82KkPHnuPjdO7bHIIP4YA9Xa49lXRDLSygSzQmTMTYt6czOvcfcPA/+GWXrRyhgOfafjQtZhRAjTEwhd6wfdfUlC1XHAbOn4BODuk3OWDlOGrFskjEVjerWo9yzmKYt0OJEYLzJ3z+26sS4LWVN8kOBgP0/xmd39VrO5xrpNiAlDI+TZw+FEtLfFkynPJcDX5myXxswUdz/b3U8CHsoL14o6+ZfQE0PfSXcm/uvRCHkCMbPfAB9z92PNbDqR1saIHHkT7tY8wXQRrq1jPAvx34QW9SYQi7Q0XyLi9h7oLXPP9RktZAkx/kggTzDJrfiLwGaEVUE+ZnBvIpUJIeY8UllMPE8RI8l5CffguX0xTwgxQUggTyDJ/OtbREzitdz98ZoqQoj/YqSymEDM7GLgIz6x+QeFEM8SJJCFEKInyA5ZCCF6ggSyEEL0BAlkIYToCRLIQgjREySQhRCiJ0ggCyFET/h/ueab8f/R8B8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 75)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope    ...    EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl    ...                0         0           0   \n",
       "1    AllPub       FR2       Gtl    ...                0         0           0   \n",
       "2    AllPub    Inside       Gtl    ...                0         0           0   \n",
       "3    AllPub    Corner       Gtl    ...              272         0           0   \n",
       "4    AllPub       FR2       Gtl    ...                0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal    208500  \n",
       "1        0       0       5    2007        WD         Normal    181500  \n",
       "2        0       0       9    2008        WD         Normal    223500  \n",
       "3        0       0       2    2006        WD        Abnorml    140000  \n",
       "4        0       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##HAndle Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['MSZoning','Street','LotShape','LandContour','Utilities','LotConfig','LandSlope','Neighborhood',\n",
    "         'Condition2','BldgType','Condition1','HouseStyle','SaleType',\n",
    "        'SaleCondition','ExterCond',\n",
    "         'ExterQual','Foundation','BsmtQual','BsmtCond','BsmtExposure','BsmtFinType1','BsmtFinType2',\n",
    "        'RoofStyle','RoofMatl','Exterior1st','Exterior2nd','MasVnrType','Heating','HeatingQC',\n",
    "         'CentralAir',\n",
    "         'Electrical','KitchenQual','Functional',\n",
    "         'FireplaceQu','GarageType','GarageFinish','GarageQual','GarageCond','PavedDrive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_onehot_multcols(multcolumns):\n",
    "    df_final=final_df\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(final_df[fields],drop_first=True)\n",
    "        \n",
    "        final_df.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            df_final=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            df_final=pd.concat([df_final,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    df_final=pd.concat([final_df,df_final],axis=1)\n",
    "        \n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine Test Data \n",
    "\n",
    "test_df=pd.read_csv('formulatedtest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 74)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          20       RH         80.0    11622   Pave      Reg         Lvl   \n",
       "1          20       RL         81.0    14267   Pave      IR1         Lvl   \n",
       "2          60       RL         74.0    13830   Pave      IR1         Lvl   \n",
       "3          60       RL         78.0     9978   Pave      IR1         Lvl   \n",
       "4         120       RL         43.0     5005   Pave      IR1         HLS   \n",
       "\n",
       "  Utilities LotConfig LandSlope      ...      OpenPorchSF EnclosedPorch  \\\n",
       "0    AllPub    Inside       Gtl      ...                0             0   \n",
       "1    AllPub    Corner       Gtl      ...               36             0   \n",
       "2    AllPub    Inside       Gtl      ...               34             0   \n",
       "3    AllPub    Inside       Gtl      ...               36             0   \n",
       "4    AllPub    Inside       Gtl      ...               82             0   \n",
       "\n",
       "  3SsnPorch ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType  \\\n",
       "0         0         120        0        0       6    2010        WD   \n",
       "1         0           0        0    12500       6    2010        WD   \n",
       "2         0           0        0        0       3    2010        WD   \n",
       "3         0           0        0        0       6    2010        WD   \n",
       "4         0         144        0        0       1    2010        WD   \n",
       "\n",
       "  SaleCondition  \n",
       "0        Normal  \n",
       "1        Normal  \n",
       "2        Normal  \n",
       "3        Normal  \n",
       "4        Normal  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "final_df=pd.concat([df,test_df],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       208500.0\n",
       "1       181500.0\n",
       "2       223500.0\n",
       "3       140000.0\n",
       "4       250000.0\n",
       "5       143000.0\n",
       "6       307000.0\n",
       "7       200000.0\n",
       "8       129900.0\n",
       "9       118000.0\n",
       "10      129500.0\n",
       "11      345000.0\n",
       "12      144000.0\n",
       "13      279500.0\n",
       "14      157000.0\n",
       "15      132000.0\n",
       "16      149000.0\n",
       "18      159000.0\n",
       "19      139000.0\n",
       "20      325300.0\n",
       "21      139400.0\n",
       "22      230000.0\n",
       "23      129900.0\n",
       "24      154000.0\n",
       "25      256300.0\n",
       "26      134800.0\n",
       "27      306000.0\n",
       "28      207500.0\n",
       "29       68500.0\n",
       "30       40000.0\n",
       "          ...   \n",
       "1429         NaN\n",
       "1430         NaN\n",
       "1431         NaN\n",
       "1432         NaN\n",
       "1433         NaN\n",
       "1434         NaN\n",
       "1435         NaN\n",
       "1436         NaN\n",
       "1437         NaN\n",
       "1438         NaN\n",
       "1439         NaN\n",
       "1440         NaN\n",
       "1441         NaN\n",
       "1442         NaN\n",
       "1443         NaN\n",
       "1444         NaN\n",
       "1445         NaN\n",
       "1446         NaN\n",
       "1447         NaN\n",
       "1448         NaN\n",
       "1449         NaN\n",
       "1450         NaN\n",
       "1451         NaN\n",
       "1452         NaN\n",
       "1453         NaN\n",
       "1454         NaN\n",
       "1455         NaN\n",
       "1456         NaN\n",
       "1457         NaN\n",
       "1458         NaN\n",
       "Name: SalePrice, Length: 2881, dtype: float64"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 75)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition2\n",
      "BldgType\n",
      "Condition1\n",
      "HouseStyle\n",
      "SaleType\n",
      "SaleCondition\n",
      "ExterCond\n",
      "ExterQual\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n"
     ]
    }
   ],
   "source": [
    "final_df=category_onehot_multcols(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 235)"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df =final_df.loc[:,~final_df.columns.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>272</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>796</td>\n",
       "      <td>566</td>\n",
       "      <td>320</td>\n",
       "      <td>1</td>\n",
       "      <td>732.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1694</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1369.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>317.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1107</td>\n",
       "      <td>983</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>859.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>228</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1022</td>\n",
       "      <td>752</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>952.0</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1077</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>851.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1040</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>906.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1182</td>\n",
       "      <td>1142</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>998.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>912</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>737.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1494</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1494.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1253</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>733.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>832.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>578.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1114</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>646.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1339</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>504.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>525.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1158</td>\n",
       "      <td>1218</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1158.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1108</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>637.0</td>\n",
       "      <td>205</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1795</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>840.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>188.0</td>\n",
       "      <td>668.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>204.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1566.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>234.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1218.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1277.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>649</td>\n",
       "      <td>668</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>649.0</td>\n",
       "      <td>172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>641</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1430</th>\n",
       "      <td>967</td>\n",
       "      <td>671</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>967.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1431</th>\n",
       "      <td>729</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1432</th>\n",
       "      <td>1060</td>\n",
       "      <td>336</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>660.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1433</th>\n",
       "      <td>576</td>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>1778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1573.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>1646</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1564.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>1625</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>776.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>849.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>1664</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1664.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>1491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1491.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>1210</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>1650</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>909.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>723.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>1403</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1136.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>1960</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>1838</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1455.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>383.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>1368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>616</td>\n",
       "      <td>688</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1447</th>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>441.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>423.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>1652</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1503.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>630</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>522.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>1360</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>119.0</td>\n",
       "      <td>344.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>641.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1452</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>408.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>546</td>\n",
       "      <td>546</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>252.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>294.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>337.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>996</td>\n",
       "      <td>1004</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>758.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2881 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0          856       854          0             3       706.0         0.0   \n",
       "1         1262         0          0             3       978.0         0.0   \n",
       "2          920       866          0             3       486.0         0.0   \n",
       "3          961       756          0             3       216.0         0.0   \n",
       "4         1145      1053          0             4       655.0         0.0   \n",
       "5          796       566        320             1       732.0         0.0   \n",
       "6         1694         0          0             3      1369.0         0.0   \n",
       "7         1107       983          0             3       859.0        32.0   \n",
       "8         1022       752          0             2         0.0         0.0   \n",
       "9         1077         0          0             2       851.0         0.0   \n",
       "10        1040         0          0             3       906.0         0.0   \n",
       "11        1182      1142          0             4       998.0         0.0   \n",
       "12         912         0          0             2       737.0         0.0   \n",
       "13        1494         0          0             3         0.0         0.0   \n",
       "14        1253         0          0             2       733.0         0.0   \n",
       "15         854         0          0             2         0.0         0.0   \n",
       "16        1004         0          0             2       578.0         0.0   \n",
       "18        1114         0          0             3       646.0         0.0   \n",
       "19        1339         0          0             3       504.0         0.0   \n",
       "20        1158      1218          0             4         0.0         0.0   \n",
       "21        1108         0          0             3         0.0         0.0   \n",
       "22        1795         0          0             3         0.0         0.0   \n",
       "23        1060         0          0             3       840.0         0.0   \n",
       "24        1060         0          0             3       188.0       668.0   \n",
       "25        1600         0          0             3         0.0         0.0   \n",
       "26         900         0          0             3       234.0       486.0   \n",
       "27        1704         0          0             3      1218.0         0.0   \n",
       "28        1600         0          0             2      1277.0         0.0   \n",
       "29         520         0          0             1         0.0         0.0   \n",
       "30         649       668          0             3         0.0         0.0   \n",
       "...        ...       ...        ...           ...         ...         ...   \n",
       "1429       641         0          0             2         0.0         0.0   \n",
       "1430       967       671          0             4         0.0         0.0   \n",
       "1431       729         0          0             2         0.0         0.0   \n",
       "1432      1060       336          0             4         0.0         0.0   \n",
       "1433       576       360          0             2         0.0         0.0   \n",
       "1434      1778         0          0             2      1573.0         0.0   \n",
       "1435      1646         0          0             2      1564.0         0.0   \n",
       "1436      1625         0          0             3       776.0         0.0   \n",
       "1437      1664         0          0             4         0.0         0.0   \n",
       "1438      1491         0          0             3         0.0         0.0   \n",
       "1439      1210         0          0             3       576.0         0.0   \n",
       "1440      1650         0          0             2       909.0         0.0   \n",
       "1441      1403         0          0             2      1136.0       116.0   \n",
       "1442      1960         0          0             3      1350.0         0.0   \n",
       "1443      1838         0          0             3      1455.0         0.0   \n",
       "1444      1600         0          0             3         0.0         0.0   \n",
       "1445      1368         0          0             2      1243.0         0.0   \n",
       "1446       616       688          0             3         0.0         0.0   \n",
       "1447       874         0          0             3       441.0         0.0   \n",
       "1448      1652         0          0             4       149.0         0.0   \n",
       "1449       630         0          0             1       522.0         0.0   \n",
       "1450       546       546          0             3       252.0         0.0   \n",
       "1451      1360         0          0             3       119.0       344.0   \n",
       "1452       546       546          0             3       408.0         0.0   \n",
       "1453       546       546          0             3         0.0         0.0   \n",
       "1454       546       546          0             3         0.0         0.0   \n",
       "1455       546       546          0             3       252.0         0.0   \n",
       "1456      1224         0          0             4      1224.0         0.0   \n",
       "1457       970         0          0             3       337.0         0.0   \n",
       "1458       996      1004          0             3       758.0         0.0   \n",
       "\n",
       "      BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  \\\n",
       "0              1.0           0.0      150.0              0 ...     0     0   \n",
       "1              0.0           1.0      284.0              0 ...     0     0   \n",
       "2              1.0           0.0      434.0              0 ...     0     0   \n",
       "3              1.0           0.0      540.0            272 ...     0     0   \n",
       "4              1.0           0.0      490.0              0 ...     0     0   \n",
       "5              1.0           0.0       64.0              0 ...     0     0   \n",
       "6              1.0           0.0      317.0              0 ...     0     0   \n",
       "7              1.0           0.0      216.0            228 ...     0     0   \n",
       "8              0.0           0.0      952.0            205 ...     1     0   \n",
       "9              1.0           0.0      140.0              0 ...     0     0   \n",
       "10             1.0           0.0      134.0              0 ...     0     0   \n",
       "11             1.0           0.0      177.0              0 ...     0     0   \n",
       "12             1.0           0.0      175.0              0 ...     0     0   \n",
       "13             0.0           0.0     1494.0              0 ...     0     0   \n",
       "14             1.0           0.0      520.0            176 ...     0     0   \n",
       "15             0.0           0.0      832.0              0 ...     0     0   \n",
       "16             1.0           0.0      426.0              0 ...     0     0   \n",
       "18             1.0           0.0      468.0              0 ...     0     0   \n",
       "19             0.0           0.0      525.0              0 ...     1     0   \n",
       "20             0.0           0.0     1158.0              0 ...     0     0   \n",
       "21             0.0           0.0      637.0            205 ...     0     0   \n",
       "22             0.0           0.0     1777.0              0 ...     0     0   \n",
       "23             1.0           0.0      200.0              0 ...     0     0   \n",
       "24             1.0           0.0      204.0              0 ...     0     0   \n",
       "25             0.0           0.0     1566.0              0 ...     0     0   \n",
       "26             0.0           1.0      180.0              0 ...     0     0   \n",
       "27             1.0           0.0      486.0              0 ...     0     0   \n",
       "28             1.0           0.0      207.0              0 ...     0     0   \n",
       "29             0.0           0.0      520.0             87 ...     0     0   \n",
       "30             0.0           0.0      649.0            172 ...     0     0   \n",
       "...            ...           ...        ...            ... ...   ...   ...   \n",
       "1429           0.0           0.0      641.0             70 ...     0     0   \n",
       "1430           0.0           0.0      967.0              0 ...     0     0   \n",
       "1431           0.0           0.0        0.0             23 ...     0     0   \n",
       "1432           0.0           0.0      660.0              0 ...     0     1   \n",
       "1433           0.0           0.0      216.0              0 ...     0     0   \n",
       "1434           2.0           0.0        0.0              0 ...     0     0   \n",
       "1435           1.0           1.0       30.0              0 ...     0     0   \n",
       "1436           0.0           1.0      849.0              0 ...     0     0   \n",
       "1437           0.0           0.0     1664.0              0 ...     0     0   \n",
       "1438           0.0           0.0     1491.0              0 ...     0     0   \n",
       "1439           1.0           0.0      552.0              0 ...     0     0   \n",
       "1440           1.0           0.0      723.0              0 ...     0     0   \n",
       "1441           1.0           0.0      129.0              0 ...     0     0   \n",
       "1442           1.0           0.0      378.0              0 ...     0     0   \n",
       "1443           1.0           0.0      383.0              0 ...     0     0   \n",
       "1444           0.0           0.0        0.0            135 ...     0     0   \n",
       "1445           2.0           0.0       45.0              0 ...     0     0   \n",
       "1446           0.0           0.0      264.0              0 ...     0     0   \n",
       "1447           1.0           0.0      423.0              0 ...     0     0   \n",
       "1448           0.0           0.0     1503.0              0 ...     0     0   \n",
       "1449           1.0           0.0      108.0              0 ...     0     0   \n",
       "1450           0.0           0.0      294.0              0 ...     0     0   \n",
       "1451           1.0           0.0      641.0              0 ...     0     0   \n",
       "1452           0.0           0.0      138.0              0 ...     0     0   \n",
       "1453           0.0           0.0      546.0              0 ...     0     0   \n",
       "1454           0.0           0.0      546.0              0 ...     0     0   \n",
       "1455           0.0           0.0      294.0              0 ...     0     0   \n",
       "1456           1.0           0.0        0.0              0 ...     0     0   \n",
       "1457           0.0           1.0      575.0              0 ...     0     0   \n",
       "1458           0.0           0.0      238.0              0 ...     0     0   \n",
       "\n",
       "      Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1       1        0        0        0       0    1  0  \n",
       "1       1       1        0        0        0       0    1  0  \n",
       "2       1       1        0        0        0       0    1  0  \n",
       "3       1       0        0        0        0       1    0  0  \n",
       "4       1       1        0        0        0       0    1  0  \n",
       "5       1       1        0        0        0       0    0  0  \n",
       "6       1       1        0        0        0       0    1  0  \n",
       "7       1       1        0        0        0       0    1  0  \n",
       "8       0       0        0        0        0       1    0  0  \n",
       "9       1       1        0        0        0       0    1  0  \n",
       "10      1       0        0        0        0       1    0  0  \n",
       "11      1       0        0        1        0       0    0  0  \n",
       "12      1       0        0        0        0       1    0  0  \n",
       "13      1       1        0        0        0       0    1  0  \n",
       "14      1       1        0        0        0       0    1  0  \n",
       "15      1       0        0        0        0       1    0  0  \n",
       "16      1       1        0        0        0       0    0  0  \n",
       "18      1       0        0        0        0       1    0  0  \n",
       "19      0       1        0        0        0       0    0  0  \n",
       "20      1       0        0        1        0       0    1  0  \n",
       "21      1       1        0        0        0       0    0  0  \n",
       "22      1       1        0        0        0       0    1  0  \n",
       "23      1       1        0        0        0       0    0  0  \n",
       "24      1       1        0        0        0       0    0  0  \n",
       "25      1       1        0        0        0       0    1  0  \n",
       "26      1       0        0        0        0       1    0  0  \n",
       "27      1       1        0        0        0       0    1  0  \n",
       "28      1       1        0        0        0       0    1  0  \n",
       "29      1       0        0        0        0       1    0  0  \n",
       "30      1       0        0        0        0       1    0  0  \n",
       "...   ...     ...      ...      ...      ...     ...  ... ..  \n",
       "1429    1       0        0        0        0       1    0  0  \n",
       "1430    1       0        0        0        0       1    0  0  \n",
       "1431    0       1        0        0        0       0    0  0  \n",
       "1432    0       1        0        0        0       0    0  0  \n",
       "1433    1       1        0        0        0       0    0  0  \n",
       "1434    1       1        0        0        0       0    0  0  \n",
       "1435    1       1        0        0        0       0    0  0  \n",
       "1436    1       1        0        0        0       0    0  0  \n",
       "1437    1       0        0        0        0       0    0  0  \n",
       "1438    1       1        0        0        0       0    1  0  \n",
       "1439    1       1        0        0        0       0    0  0  \n",
       "1440    1       1        0        0        0       0    0  0  \n",
       "1441    1       1        0        0        0       0    0  0  \n",
       "1442    1       1        0        0        0       0    0  0  \n",
       "1443    1       1        0        0        0       0    0  0  \n",
       "1444    0       1        0        0        0       0    0  0  \n",
       "1445    1       1        0        0        0       0    0  0  \n",
       "1446    1       0        0        1        0       0    1  0  \n",
       "1447    1       1        0        0        0       0    1  0  \n",
       "1448    1       0        0        0        0       0    0  0  \n",
       "1449    1       1        0        0        0       0    0  0  \n",
       "1450    1       1        0        0        0       0    0  0  \n",
       "1451    1       1        0        0        0       0    1  0  \n",
       "1452    1       0        0        0        1       0    0  0  \n",
       "1453    1       1        0        0        0       0    0  0  \n",
       "1454    1       1        0        0        0       0    0  0  \n",
       "1455    1       0        0        0        1       0    0  0  \n",
       "1456    1       0        0        0        0       1    0  0  \n",
       "1457    1       1        0        0        0       0    0  0  \n",
       "1458    1       1        0        0        0       0    0  0  \n",
       "\n",
       "[2881 rows x 175 columns]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=final_df.iloc[:1422,:]\n",
    "df_Test=final_df.iloc[1422:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>856</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1262</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>920</td>\n",
       "      <td>866</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>961</td>\n",
       "      <td>756</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>272</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1145</td>\n",
       "      <td>1053</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       856       854          0             3       706.0         0.0   \n",
       "1      1262         0          0             3       978.0         0.0   \n",
       "2       920       866          0             3       486.0         0.0   \n",
       "3       961       756          0             3       216.0         0.0   \n",
       "4      1145      1053          0             4       655.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  Typ  \\\n",
       "0           1.0           0.0      150.0              0 ...     0     0    1   \n",
       "1           0.0           1.0      284.0              0 ...     0     0    1   \n",
       "2           1.0           0.0      434.0              0 ...     0     0    1   \n",
       "3           1.0           0.0      540.0            272 ...     0     0    1   \n",
       "4           1.0           0.0      490.0              0 ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    1  0  \n",
       "1       1        0        0        0       0    1  0  \n",
       "2       1        0        0        0       0    1  0  \n",
       "3       0        0        0        0       1    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  Typ  \\\n",
       "0           0.0           0.0      270.0              0 ...     0     0    1   \n",
       "1           0.0           0.0      406.0              0 ...     0     0    1   \n",
       "2           0.0           0.0      137.0              0 ...     0     0    1   \n",
       "3           0.0           0.0      324.0              0 ...     0     0    1   \n",
       "4           0.0           0.0     1017.0              0 ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 175)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediciton and selecting the Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "classifier=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "regressor=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.05,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the random search with 4-fold cross validation\n",
    "random_cv = RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=4)]: Done  64 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=4)]: Done 154 tasks      | elapsed:  5.3min\n",
      "[Parallel(n_jobs=4)]: Done 250 out of 250 | elapsed:  7.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "          estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "          fit_params=None, iid='warn', n_iter=50, n_jobs=4,\n",
       "          param_distributions={'n_estimators': [100, 500, 900, 1100, 1500], 'max_depth': [2, 3, 5, 10, 15], 'learning_rate': [0.05, 0.1, 0.15, 0.2], 'min_child_weight': [1, 2, 3, 4], 'booster': ['gbtree', 'gblinear'], 'base_score': [0.25, 0.5, 0.75, 1]},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score=True, scoring='neg_mean_absolute_error',\n",
       "          verbose=5)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.05, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=2, min_child_weight=1, missing=None, n_estimators=900,\n",
       "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 174)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121033.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155717.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185616.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189161.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>175323.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch      ...        Min2  \\\n",
       "0           0.0           0.0      270.0              0      ...           0   \n",
       "1           0.0           0.0      406.0              0      ...           0   \n",
       "2           0.0           0.0      137.0              0      ...           0   \n",
       "3           0.0           0.0      324.0              0      ...           0   \n",
       "4           0.0           0.0     1017.0              0      ...           0   \n",
       "\n",
       "   Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P      SalePrice  \n",
       "0    1       1        0        0        0       0    0  0  121033.398438  \n",
       "1    1       1        0        0        0       0    0  0  155717.390625  \n",
       "2    1       1        0        0        0       0    0  0  185616.859375  \n",
       "3    1       1        0        0        0       0    0  0  189161.546875  \n",
       "4    1       1        0        0        0       0    1  0  175323.750000  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min1</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 174 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch ...  Min1  Min2  Typ  \\\n",
       "0           0.0           0.0      270.0              0 ...     0     0    1   \n",
       "1           0.0           0.0      406.0              0 ...     0     0    1   \n",
       "2           0.0           0.0      137.0              0 ...     0     0    1   \n",
       "3           0.0           0.0      324.0              0 ...     0     0    1   \n",
       "4           0.0           0.0     1017.0              0 ...     0     0    1   \n",
       "\n",
       "   Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P  \n",
       "0       1        0        0        0       0    0  0  \n",
       "1       1        0        0        0       0    0  0  \n",
       "2       1        0        0        0       0    0  0  \n",
       "3       1        0        0        0       0    0  0  \n",
       "4       1        0        0        0       0    1  0  \n",
       "\n",
       "[5 rows x 174 columns]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.drop(['SalePrice'],axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=regressor.predict(df_Test.drop(['SalePrice'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([119179.125, 158328.88 , 183704.81 , ..., 165757.22 , 118693.11 ,\n",
       "       230294.19 ], dtype=float32)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred=pd.DataFrame(ann_pred)\n",
    "sub_df=pd.read_csv('sample_submission.csv')\n",
    "datasets=pd.concat([sub_df['Id'],pred],axis=1)\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.columns=['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df=df_Train['SalePrice'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.column=['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=pd.concat([df_Train,temp_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>...</th>\n",
       "      <th>Min2</th>\n",
       "      <th>Typ</th>\n",
       "      <th>Attchd</th>\n",
       "      <th>Basment</th>\n",
       "      <th>BuiltIn</th>\n",
       "      <th>CarPort</th>\n",
       "      <th>Detchd</th>\n",
       "      <th>RFn</th>\n",
       "      <th>P</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121033.398438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>155717.390625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>928</td>\n",
       "      <td>701</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>185616.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>926</td>\n",
       "      <td>678</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189161.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>175323.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  3SsnPorch  BedroomAbvGr  BsmtFinSF1  BsmtFinSF2  \\\n",
       "0       896         0          0             2       468.0       144.0   \n",
       "1      1329         0          0             3       923.0         0.0   \n",
       "2       928       701          0             3       791.0         0.0   \n",
       "3       926       678          0             3       602.0         0.0   \n",
       "4      1280         0          0             2       263.0         0.0   \n",
       "\n",
       "   BsmtFullBath  BsmtHalfBath  BsmtUnfSF  EnclosedPorch      ...        Min2  \\\n",
       "0           0.0           0.0      270.0              0      ...           0   \n",
       "1           0.0           0.0      406.0              0      ...           0   \n",
       "2           0.0           0.0      137.0              0      ...           0   \n",
       "3           0.0           0.0      324.0              0      ...           0   \n",
       "4           0.0           0.0     1017.0              0      ...           0   \n",
       "\n",
       "   Typ  Attchd  Basment  BuiltIn  CarPort  Detchd  RFn  P      SalePrice  \n",
       "0    1       1        0        0        0       0    0  0  121033.398438  \n",
       "1    1       1        0        0        0       0    0  0  155717.390625  \n",
       "2    1       1        0        0        0       0    0  0  185616.859375  \n",
       "3    1       1        0        0        0       0    0  0  189161.546875  \n",
       "4    1       1        0        0        0       0    1  0  175323.750000  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Test=pd.concat([df_Test,pred],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 175)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=pd.concat([df_Train,df_Test],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Neural Network Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=174, units=50, kernel_initializer=\"he_uniform\")`\n",
      "  del sys.path[0]\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:16: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=25, kernel_initializer=\"he_uniform\")`\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=50, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1, kernel_initializer=\"he_uniform\")`\n",
      "C:\\Users\\krish.naik\\AppData\\Local\\Continuum\\anaconda3\\envs\\myenv\\lib\\site-packages\\ipykernel_launcher.py:27: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2304 samples, validate on 577 samples\n",
      "Epoch 1/1000\n",
      "2304/2304 [==============================] - 2s 1ms/step - loss: 113530.5093 - val_loss: 56624.8765\n",
      "Epoch 2/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 62615.1298 - val_loss: 50444.1900\n",
      "Epoch 3/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 56279.5739 - val_loss: 44504.8296\n",
      "Epoch 4/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 50261.0310 - val_loss: 39335.5723\n",
      "Epoch 5/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 44449.5163 - val_loss: 35396.5539\n",
      "Epoch 6/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 40090.4315 - val_loss: 35178.2237\n",
      "Epoch 7/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 37493.4126 - val_loss: 31983.3301\n",
      "Epoch 8/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 36462.1401 - val_loss: 34241.1639\n",
      "Epoch 9/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 35635.4539 - val_loss: 32087.6040\n",
      "Epoch 10/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 35851.5885 - val_loss: 32125.1113\n",
      "Epoch 11/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 35622.6530 - val_loss: 31914.6602\n",
      "Epoch 12/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 35187.7144 - val_loss: 31882.3983\n",
      "Epoch 13/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 35196.1213 - val_loss: 32342.4395\n",
      "Epoch 14/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 34929.6660 - val_loss: 31565.0875\n",
      "Epoch 15/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 34672.9052 - val_loss: 32177.3833\n",
      "Epoch 16/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 34501.2563 - val_loss: 31293.5959\n",
      "Epoch 17/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 34804.2316 - val_loss: 31182.3204\n",
      "Epoch 18/1000\n",
      "2304/2304 [==============================] - 2s 778us/step - loss: 34455.4584 - val_loss: 31376.9020\n",
      "Epoch 19/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 34377.8071 - val_loss: 31301.4047\n",
      "Epoch 20/1000\n",
      "2304/2304 [==============================] - 1s 477us/step - loss: 34164.2543 - val_loss: 31142.9020\n",
      "Epoch 21/1000\n",
      "2304/2304 [==============================] - 1s 469us/step - loss: 34009.0316 - val_loss: 31243.3016\n",
      "Epoch 22/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 33660.4401 - val_loss: 31494.8445\n",
      "Epoch 23/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 33812.4372 - val_loss: 31299.1932\n",
      "Epoch 24/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 33589.9288 - val_loss: 31848.2731\n",
      "Epoch 25/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 33607.1809 - val_loss: 30390.6748\n",
      "Epoch 26/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 33473.9579 - val_loss: 30910.1593\n",
      "Epoch 27/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 33236.2349 - val_loss: 30219.5441\n",
      "Epoch 28/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 33243.2710 - val_loss: 30179.0993\n",
      "Epoch 29/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 32929.2295 - val_loss: 30128.3545\n",
      "Epoch 30/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 32963.0511 - val_loss: 30510.0357\n",
      "Epoch 31/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 32787.1626 - val_loss: 29853.5188\n",
      "Epoch 32/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 32766.8486 - val_loss: 30704.6890\n",
      "Epoch 33/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 32790.5330 - val_loss: 30381.5674\n",
      "Epoch 34/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 32740.6885 - val_loss: 29614.6660\n",
      "Epoch 35/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 32658.3221 - val_loss: 30323.1913\n",
      "Epoch 36/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 32570.0888 - val_loss: 30407.4534\n",
      "Epoch 37/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 32189.7531 - val_loss: 30379.3509\n",
      "Epoch 38/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 32140.4911 - val_loss: 29347.5356\n",
      "Epoch 39/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 31913.3835 - val_loss: 29861.8741\n",
      "Epoch 40/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 32135.0634 - val_loss: 29108.2475\n",
      "Epoch 41/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 32026.9856 - val_loss: 29142.3169\n",
      "Epoch 42/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 31792.7488 - val_loss: 29323.2182\n",
      "Epoch 43/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 31622.7127 - val_loss: 29028.4757\n",
      "Epoch 44/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 31769.7568 - val_loss: 29493.1864\n",
      "Epoch 45/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 31732.7656 - val_loss: 29812.4935\n",
      "Epoch 46/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 31434.8387 - val_loss: 28903.6488\n",
      "Epoch 47/1000\n",
      "2304/2304 [==============================] - 1s 414us/step - loss: 31234.3539 - val_loss: 28895.0965\n",
      "Epoch 48/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 31151.4855 - val_loss: 28861.3638\n",
      "Epoch 49/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 31274.5573 - val_loss: 29427.3137\n",
      "Epoch 50/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 31510.8220 - val_loss: 28567.3384\n",
      "Epoch 51/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 31460.1977 - val_loss: 28814.4977\n",
      "Epoch 52/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 31085.8429 - val_loss: 28524.2395\n",
      "Epoch 53/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 30989.9977 - val_loss: 28568.5788\n",
      "Epoch 54/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 31092.4584 - val_loss: 28378.7455\n",
      "Epoch 55/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 30932.9268 - val_loss: 30094.5473\n",
      "Epoch 56/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 30684.4676 - val_loss: 28414.4087\n",
      "Epoch 57/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 30493.6564 - val_loss: 29508.0253\n",
      "Epoch 58/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 30652.6024 - val_loss: 28326.5143\n",
      "Epoch 59/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 30778.1669 - val_loss: 28056.4234\n",
      "Epoch 60/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 30424.7307 - val_loss: 28010.0378\n",
      "Epoch 61/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 30072.8579 - val_loss: 28027.6187\n",
      "Epoch 62/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 30334.3219 - val_loss: 28459.9857\n",
      "Epoch 63/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 30427.8750 - val_loss: 29863.5684\n",
      "Epoch 64/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 30285.2018 - val_loss: 28957.1549\n",
      "Epoch 65/1000\n",
      "2304/2304 [==============================] - 1s 417us/step - loss: 30310.4877 - val_loss: 28183.0357\n",
      "Epoch 66/1000\n",
      "2304/2304 [==============================] - 1s 405us/step - loss: 30276.2501 - val_loss: 27665.3018\n",
      "Epoch 67/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 29832.1718 - val_loss: 27712.5372\n",
      "Epoch 68/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 30272.4041 - val_loss: 27718.7824\n",
      "Epoch 69/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 30113.7119 - val_loss: 28000.3839\n",
      "Epoch 70/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 29942.6214 - val_loss: 27786.2428\n",
      "Epoch 71/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 29859.0674 - val_loss: 27215.5401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 29209.5491 - val_loss: 27173.5760\n",
      "Epoch 73/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 29919.4843 - val_loss: 27220.3691\n",
      "Epoch 74/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 29509.6134 - val_loss: 27340.0882\n",
      "Epoch 75/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 29708.4845 - val_loss: 27312.6990\n",
      "Epoch 76/1000\n",
      "2304/2304 [==============================] - 1s 473us/step - loss: 29519.9725 - val_loss: 27508.6494\n",
      "Epoch 77/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 29357.4566 - val_loss: 26867.6287\n",
      "Epoch 78/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 29159.6736 - val_loss: 26893.8640\n",
      "Epoch 79/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 29366.9112 - val_loss: 26603.1912\n",
      "Epoch 80/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 29120.4931 - val_loss: 26661.9235\n",
      "Epoch 81/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 28946.7935 - val_loss: 27871.8099\n",
      "Epoch 82/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 29138.3855 - val_loss: 26531.3914\n",
      "Epoch 83/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 28846.1910 - val_loss: 28481.5947\n",
      "Epoch 84/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 29017.1691 - val_loss: 26508.0993\n",
      "Epoch 85/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 28775.6919 - val_loss: 26779.5843\n",
      "Epoch 86/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 29089.2547 - val_loss: 27172.3217\n",
      "Epoch 87/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 28686.1871 - val_loss: 26091.4350\n",
      "Epoch 88/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 28698.4660 - val_loss: 26102.4028\n",
      "Epoch 89/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 28699.3697 - val_loss: 26289.4353\n",
      "Epoch 90/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 28489.5871 - val_loss: 27897.5505\n",
      "Epoch 91/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 28665.1914 - val_loss: 25854.9589\n",
      "Epoch 92/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 28285.7090 - val_loss: 25977.9663\n",
      "Epoch 93/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 28285.7983 - val_loss: 25438.4628\n",
      "Epoch 94/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 28321.3720 - val_loss: 25585.6818\n",
      "Epoch 95/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 28190.3902 - val_loss: 25334.2817\n",
      "Epoch 96/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 28360.6425 - val_loss: 25095.3392\n",
      "Epoch 97/1000\n",
      "2304/2304 [==============================] - 1s 468us/step - loss: 28196.4608 - val_loss: 24977.6499\n",
      "Epoch 98/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 28143.1103 - val_loss: 24957.5144\n",
      "Epoch 99/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 28541.725 - 1s 465us/step - loss: 28404.1788 - val_loss: 25377.6330\n",
      "Epoch 100/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 27923.1122 - val_loss: 25035.9833\n",
      "Epoch 101/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 28224.6294 - val_loss: 24864.9644\n",
      "Epoch 102/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 27838.1132 - val_loss: 26435.8536\n",
      "Epoch 103/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 27936.2079 - val_loss: 24885.9012\n",
      "Epoch 104/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 27583.212 - 1s 450us/step - loss: 27619.0787 - val_loss: 24613.4044\n",
      "Epoch 105/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 27628.1560 - val_loss: 24228.4823\n",
      "Epoch 106/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 27878.6943 - val_loss: 24845.3175\n",
      "Epoch 107/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 27493.7438 - val_loss: 24612.2324\n",
      "Epoch 108/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 27134.2120 - val_loss: 25914.3079\n",
      "Epoch 109/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 27448.0619 - val_loss: 23640.7174\n",
      "Epoch 110/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 27225.6602 - val_loss: 24300.4790\n",
      "Epoch 111/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 27457.5783 - val_loss: 23591.0836\n",
      "Epoch 112/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 27562.5854 - val_loss: 23601.4916\n",
      "Epoch 113/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 26970.8130 - val_loss: 23496.5879\n",
      "Epoch 114/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 27141.8372 - val_loss: 24716.6597\n",
      "Epoch 115/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 26687.5030 - val_loss: 25936.5065\n",
      "Epoch 116/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 26811.0217 - val_loss: 23067.7963\n",
      "Epoch 117/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 26862.9685 - val_loss: 23789.6916\n",
      "Epoch 118/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 26478.2679 - val_loss: 24595.6749\n",
      "Epoch 119/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 26766.5188 - val_loss: 23377.8840\n",
      "Epoch 120/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 26545.6570 - val_loss: 22453.2940\n",
      "Epoch 121/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 26442.3213 - val_loss: 22567.1628\n",
      "Epoch 122/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 26011.6722 - val_loss: 24087.4123\n",
      "Epoch 123/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 26506.6031 - val_loss: 22453.8540\n",
      "Epoch 124/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 26042.1024 - val_loss: 22348.5490\n",
      "Epoch 125/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 26685.7815 - val_loss: 21968.0753\n",
      "Epoch 126/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 25654.7254 - val_loss: 22398.2175\n",
      "Epoch 127/1000\n",
      "2304/2304 [==============================] - 1s 468us/step - loss: 25909.7507 - val_loss: 21961.1548\n",
      "Epoch 128/1000\n",
      "2304/2304 [==============================] - 1s 480us/step - loss: 25938.8809 - val_loss: 21437.6150\n",
      "Epoch 129/1000\n",
      "2304/2304 [==============================] - 1s 476us/step - loss: 25268.5747 - val_loss: 21907.7049\n",
      "Epoch 130/1000\n",
      "2304/2304 [==============================] - 1s 470us/step - loss: 25609.2470 - val_loss: 21246.5780\n",
      "Epoch 131/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 25023.4624 - val_loss: 24637.6923\n",
      "Epoch 132/1000\n",
      "2304/2304 [==============================] - 1s 520us/step - loss: 25366.8912 - val_loss: 21211.1705\n",
      "Epoch 133/1000\n",
      "2304/2304 [==============================] - 1s 479us/step - loss: 25424.9557 - val_loss: 21021.8191\n",
      "Epoch 134/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 25343.5929 - val_loss: 21586.6650\n",
      "Epoch 135/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 24995.2175 - val_loss: 21105.6569\n",
      "Epoch 136/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 24986.7363 - val_loss: 20605.5033\n",
      "Epoch 137/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 25225.4030 - val_loss: 20552.5941\n",
      "Epoch 138/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 25014.9195 - val_loss: 21813.1205\n",
      "Epoch 139/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 24983.0982 - val_loss: 20684.3204\n",
      "Epoch 140/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 24864.2334 - val_loss: 20245.8430\n",
      "Epoch 141/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 24915.6213 - val_loss: 19954.3808\n",
      "Epoch 142/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 24832.0423 - val_loss: 22799.6597\n",
      "Epoch 143/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 24758.2035 - val_loss: 20148.5544\n",
      "Epoch 144/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 24726.4656 - val_loss: 19816.7254\n",
      "Epoch 145/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 24342.4105 - val_loss: 21506.8392\n",
      "Epoch 146/1000\n",
      "2304/2304 [==============================] - 1s 494us/step - loss: 24704.4509 - val_loss: 19672.9874\n",
      "Epoch 147/1000\n",
      "2304/2304 [==============================] - 1s 483us/step - loss: 24873.8309 - val_loss: 19765.3019\n",
      "Epoch 148/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 24126.7666 - val_loss: 21504.0878\n",
      "Epoch 149/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 24424.1095 - val_loss: 21462.0763\n",
      "Epoch 150/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 24470.7238 - val_loss: 19617.8413\n",
      "Epoch 151/1000\n",
      "2304/2304 [==============================] - 1s 468us/step - loss: 24235.2767 - val_loss: 20478.6877\n",
      "Epoch 152/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 23886.3026 - val_loss: 19679.8546\n",
      "Epoch 153/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 24203.4083 - val_loss: 19225.7126\n",
      "Epoch 154/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 24125.6937 - val_loss: 18712.8627\n",
      "Epoch 155/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 23699.3783 - val_loss: 19005.6716\n",
      "Epoch 156/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 23628.8058 - val_loss: 20574.2034\n",
      "Epoch 157/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 23527.5995 - val_loss: 20440.9397\n",
      "Epoch 158/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 23367.5987 - val_loss: 20027.8654\n",
      "Epoch 159/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 23393.3923 - val_loss: 18406.9154\n",
      "Epoch 160/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 23547.7516 - val_loss: 19510.1907\n",
      "Epoch 161/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 23700.4968 - val_loss: 19711.2351\n",
      "Epoch 162/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 23521.9805 - val_loss: 19353.0765\n",
      "Epoch 163/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 23289.4974 - val_loss: 18495.0024\n",
      "Epoch 164/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 23146.1177 - val_loss: 18525.8958\n",
      "Epoch 165/1000\n",
      "2304/2304 [==============================] - 1s 474us/step - loss: 23378.2289 - val_loss: 18674.6753\n",
      "Epoch 166/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 22990.6150 - val_loss: 18405.3405\n",
      "Epoch 167/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 23208.1085 - val_loss: 18444.8079\n",
      "Epoch 168/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 23341.9950 - val_loss: 18214.6930\n",
      "Epoch 169/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 22968.4293 - val_loss: 18287.0789\n",
      "Epoch 170/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 23336.9285 - val_loss: 19328.6353\n",
      "Epoch 171/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 23004.5811 - val_loss: 22645.0320\n",
      "Epoch 172/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 23450.7607 - val_loss: 18237.4190\n",
      "Epoch 173/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 23322.7922 - val_loss: 18528.1455\n",
      "Epoch 174/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 22646.3451 - val_loss: 18115.4026\n",
      "Epoch 175/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 22568.9873 - val_loss: 19539.2561\n",
      "Epoch 176/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 23544.2008 - val_loss: 17933.2717\n",
      "Epoch 177/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 22497.0116 - val_loss: 17354.5006\n",
      "Epoch 178/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 22879.9811 - val_loss: 17579.1927\n",
      "Epoch 179/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 22938.6665 - val_loss: 18413.8741\n",
      "Epoch 180/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 22665.2603 - val_loss: 19428.7250\n",
      "Epoch 181/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 22319.2484 - val_loss: 17366.1969\n",
      "Epoch 182/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 22669.5232 - val_loss: 18838.8342\n",
      "Epoch 183/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 22451.1597 - val_loss: 18472.8874\n",
      "Epoch 184/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 22706.7617 - val_loss: 18255.4424\n",
      "Epoch 185/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 22957.0078 - val_loss: 17473.3416\n",
      "Epoch 186/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 22531.9464 - val_loss: 16844.6493\n",
      "Epoch 187/1000\n",
      "2304/2304 [==============================] - 1s 474us/step - loss: 22240.5742 - val_loss: 17564.5887\n",
      "Epoch 188/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 22642.6283 - val_loss: 17112.6908\n",
      "Epoch 189/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 22320.6819 - val_loss: 17639.8543\n",
      "Epoch 190/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 22117.3255 - val_loss: 17005.3269\n",
      "Epoch 191/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 22249.5553 - val_loss: 18395.3013\n",
      "Epoch 192/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 22401.0267 - val_loss: 16680.4410\n",
      "Epoch 193/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 22384.8159 - val_loss: 17162.2615\n",
      "Epoch 194/1000\n",
      "2304/2304 [==============================] - 1s 475us/step - loss: 21983.3552 - val_loss: 18605.2577\n",
      "Epoch 195/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 22257.2526 - val_loss: 17034.5954\n",
      "Epoch 196/1000\n",
      "2304/2304 [==============================] - 1s 465us/step - loss: 22122.9456 - val_loss: 17328.9022\n",
      "Epoch 197/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 22467.4348 - val_loss: 17312.1251\n",
      "Epoch 198/1000\n",
      "2304/2304 [==============================] - 1s 480us/step - loss: 22034.0424 - val_loss: 16346.6881\n",
      "Epoch 199/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 21772.8173 - val_loss: 16449.1762\n",
      "Epoch 200/1000\n",
      "2304/2304 [==============================] - 1s 466us/step - loss: 21616.0995 - val_loss: 19556.2224\n",
      "Epoch 201/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 22326.2749 - val_loss: 16196.6720\n",
      "Epoch 202/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 22678.2432 - val_loss: 16400.9500\n",
      "Epoch 203/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 21954.1421 - val_loss: 17115.8815\n",
      "Epoch 204/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 21574.3031 - val_loss: 16127.1571\n",
      "Epoch 205/1000\n",
      "2304/2304 [==============================] - 1s 480us/step - loss: 22338.9508 - val_loss: 19444.3208\n",
      "Epoch 206/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 21852.7934 - val_loss: 19308.3233\n",
      "Epoch 207/1000\n",
      "2304/2304 [==============================] - 1s 473us/step - loss: 21872.5774 - val_loss: 17685.5849\n",
      "Epoch 208/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 21486.7361 - val_loss: 16639.5072\n",
      "Epoch 209/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 21571.2908 - val_loss: 16761.9651\n",
      "Epoch 210/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 21631.3609 - val_loss: 15658.4923\n",
      "Epoch 211/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 21486.4054 - val_loss: 15814.1505\n",
      "Epoch 212/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 21541.5087 - val_loss: 17495.6494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 213/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 22039.3132 - val_loss: 18907.8804\n",
      "Epoch 214/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 21535.5008 - val_loss: 16334.5270\n",
      "Epoch 215/1000\n",
      "2304/2304 [==============================] - 1s 474us/step - loss: 21397.5464 - val_loss: 15527.8804\n",
      "Epoch 216/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20970.6127 - val_loss: 15893.2644\n",
      "Epoch 217/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 21382.1890 - val_loss: 16356.3695\n",
      "Epoch 218/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 21161.6115 - val_loss: 17358.3467\n",
      "Epoch 219/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 21313.9134 - val_loss: 16149.4819\n",
      "Epoch 220/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 21500.9419 - val_loss: 15796.3191\n",
      "Epoch 221/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 21536.2349 - val_loss: 15471.1339\n",
      "Epoch 222/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 21088.8941 - val_loss: 15343.0244\n",
      "Epoch 223/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 21667.5794 - val_loss: 17580.5199\n",
      "Epoch 224/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 20965.1858 - val_loss: 15803.6322\n",
      "Epoch 225/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 21442.6807 - val_loss: 17598.5028\n",
      "Epoch 226/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 21107.7338 - val_loss: 15927.4279\n",
      "Epoch 227/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20982.8748 - val_loss: 16270.2747\n",
      "Epoch 228/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 21420.9400 - val_loss: 15423.4538\n",
      "Epoch 229/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 20855.8819 - val_loss: 16644.8780\n",
      "Epoch 230/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 20768.6303 - val_loss: 15575.5588\n",
      "Epoch 231/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 21261.2271 - val_loss: 16437.3966\n",
      "Epoch 232/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 21497.1832 - val_loss: 15420.6945\n",
      "Epoch 233/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 20544.3840 - val_loss: 15224.6794\n",
      "Epoch 234/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 21233.0104 - val_loss: 15038.2329\n",
      "Epoch 235/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 21491.5446 - val_loss: 17434.5473\n",
      "Epoch 236/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 21326.1712 - val_loss: 16683.8884\n",
      "Epoch 237/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 21116.4700 - val_loss: 15612.9380\n",
      "Epoch 238/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 22033.4280 - val_loss: 15167.3380\n",
      "Epoch 239/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 21327.5555 - val_loss: 15373.3279\n",
      "Epoch 240/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 20829.2319 - val_loss: 15861.8656\n",
      "Epoch 241/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 20925.8254 - val_loss: 15428.4299\n",
      "Epoch 242/1000\n",
      "2304/2304 [==============================] - 1s 510us/step - loss: 21137.2842 - val_loss: 19346.3964\n",
      "Epoch 243/1000\n",
      "2304/2304 [==============================] - 1s 495us/step - loss: 20912.4358 - val_loss: 15086.4801\n",
      "Epoch 244/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 20783.2399 - val_loss: 17047.4020\n",
      "Epoch 245/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 20600.0964 - val_loss: 16235.3380\n",
      "Epoch 246/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20756.1085 - val_loss: 15630.0819\n",
      "Epoch 247/1000\n",
      "2304/2304 [==============================] - 1s 487us/step - loss: 20794.2793 - val_loss: 15813.6791\n",
      "Epoch 248/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 20578.2091 - val_loss: 14941.2435\n",
      "Epoch 249/1000\n",
      "2304/2304 [==============================] - 1s 459us/step - loss: 20526.0308 - val_loss: 17806.7003\n",
      "Epoch 250/1000\n",
      "2304/2304 [==============================] - 1s 583us/step - loss: 20334.8256 - val_loss: 18193.9887\n",
      "Epoch 251/1000\n",
      "2304/2304 [==============================] - 1s 530us/step - loss: 20293.9275 - val_loss: 17792.9437\n",
      "Epoch 252/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 20567.1465 - val_loss: 15440.0669\n",
      "Epoch 253/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 20427.0153 - val_loss: 14923.4824\n",
      "Epoch 254/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 20450.5625 - val_loss: 16042.9484\n",
      "Epoch 255/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 20198.3318 - val_loss: 16222.9939\n",
      "Epoch 256/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 20533.8341 - val_loss: 16831.9639\n",
      "Epoch 257/1000\n",
      "2304/2304 [==============================] - 1s 509us/step - loss: 20154.9191 - val_loss: 14754.8845\n",
      "Epoch 258/1000\n",
      "2304/2304 [==============================] - 1s 469us/step - loss: 20387.4427 - val_loss: 15878.7856\n",
      "Epoch 259/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 20359.2988 - val_loss: 16003.4819\n",
      "Epoch 260/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 20531.9542 - val_loss: 16200.7362\n",
      "Epoch 261/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 20018.3629 - val_loss: 15491.6521\n",
      "Epoch 262/1000\n",
      "2304/2304 [==============================] - 1s 481us/step - loss: 20267.9428 - val_loss: 15069.8928\n",
      "Epoch 263/1000\n",
      "2304/2304 [==============================] - 1s 479us/step - loss: 20530.1369 - val_loss: 15627.3145\n",
      "Epoch 264/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 20294.7257 - val_loss: 17765.7470\n",
      "Epoch 265/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 20360.8740 - val_loss: 14508.3821\n",
      "Epoch 266/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 20267.8221 - val_loss: 15420.8517\n",
      "Epoch 267/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 19862.5230 - val_loss: 14701.4737\n",
      "Epoch 268/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 19815.6728 - val_loss: 14743.0286\n",
      "Epoch 269/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 19757.1898 - val_loss: 16036.5053\n",
      "Epoch 270/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 19572.5032 - val_loss: 15336.2828\n",
      "Epoch 271/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 19700.6566 - val_loss: 15040.9445\n",
      "Epoch 272/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19473.6894 - val_loss: 15602.6384\n",
      "Epoch 273/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 19906.8170 - val_loss: 14509.2126\n",
      "Epoch 274/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 19699.7736 - val_loss: 15772.0936\n",
      "Epoch 275/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 20105.0729 - val_loss: 14584.7437\n",
      "Epoch 276/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 20147.8612 - val_loss: 15057.5087\n",
      "Epoch 277/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 19881.5120 - val_loss: 18572.5668\n",
      "Epoch 278/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19517.4842 - val_loss: 16397.4856\n",
      "Epoch 279/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 19976.7596 - val_loss: 15108.0453\n",
      "Epoch 280/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 19935.8306 - val_loss: 15692.7591\n",
      "Epoch 281/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 19793.6322 - val_loss: 14389.2686\n",
      "Epoch 282/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 19412.6952 - val_loss: 15312.0001\n",
      "Epoch 283/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 20059.2136 - val_loss: 15273.2969\n",
      "Epoch 284/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19604.2384 - val_loss: 14420.2558\n",
      "Epoch 285/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 19496.6790 - val_loss: 14708.9673\n",
      "Epoch 286/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 20049.3460 - val_loss: 16034.7254\n",
      "Epoch 287/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 19478.0735 - val_loss: 14571.8502\n",
      "Epoch 288/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 19667.3767 - val_loss: 14611.5370\n",
      "Epoch 289/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 19504.3439 - val_loss: 14015.6003\n",
      "Epoch 290/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 19758.8318 - val_loss: 16997.5221\n",
      "Epoch 291/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 19601.7732 - val_loss: 17615.9217\n",
      "Epoch 292/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 19661.4567 - val_loss: 16816.5259\n",
      "Epoch 293/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19131.7665 - val_loss: 14086.0776\n",
      "Epoch 294/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 19576.5483 - val_loss: 14701.9938\n",
      "Epoch 295/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 19444.5205 - val_loss: 14263.2803\n",
      "Epoch 296/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 19304.4485 - val_loss: 14911.7827\n",
      "Epoch 297/1000\n",
      "2304/2304 [==============================] - 2s 687us/step - loss: 19703.8128 - val_loss: 16053.4814\n",
      "Epoch 298/1000\n",
      "2304/2304 [==============================] - 1s 462us/step - loss: 19346.9465 - val_loss: 14261.0299\n",
      "Epoch 299/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 19704.9612 - val_loss: 14267.3405\n",
      "Epoch 300/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 19352.9026 - val_loss: 14148.4302\n",
      "Epoch 301/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 19498.7444 - val_loss: 14138.5259\n",
      "Epoch 302/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18726.3407 - val_loss: 15887.5956\n",
      "Epoch 303/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 19946.6447 - val_loss: 16257.2649\n",
      "Epoch 304/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 19362.7704 - val_loss: 13983.4914\n",
      "Epoch 305/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 18790.8474 - val_loss: 14023.9126\n",
      "Epoch 306/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19160.9730 - val_loss: 14827.6932\n",
      "Epoch 307/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19190.6534 - val_loss: 18906.2787\n",
      "Epoch 308/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 19401.0639 - val_loss: 14333.4869\n",
      "Epoch 309/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19238.1993 - val_loss: 19174.5764\n",
      "Epoch 310/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 20029.8387 - val_loss: 14179.8829\n",
      "Epoch 311/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 18918.1769 - val_loss: 15346.9258\n",
      "Epoch 312/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 19041.3360 - val_loss: 15424.8321\n",
      "Epoch 313/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 19119.5293 - val_loss: 14270.7577\n",
      "Epoch 314/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 19292.8256 - val_loss: 14625.2434\n",
      "Epoch 315/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 19020.3923 - val_loss: 15541.8373\n",
      "Epoch 316/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 19109.0529 - val_loss: 14618.3543\n",
      "Epoch 317/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18554.5315 - val_loss: 14239.7411\n",
      "Epoch 318/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 19012.3046 - val_loss: 14200.9190\n",
      "Epoch 319/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18846.4739 - val_loss: 14101.2692\n",
      "Epoch 320/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 18813.7599 - val_loss: 14046.8665\n",
      "Epoch 321/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 18852.2364 - val_loss: 15203.3614\n",
      "Epoch 322/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 19056.3984 - val_loss: 14890.5568\n",
      "Epoch 323/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 18563.3026 - val_loss: 13836.5927\n",
      "Epoch 324/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 19340.7887 - val_loss: 14266.8893\n",
      "Epoch 325/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 19060.3305 - val_loss: 15360.9089\n",
      "Epoch 326/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 18662.2458 - val_loss: 14017.1838\n",
      "Epoch 327/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 18428.4088 - val_loss: 14745.7661\n",
      "Epoch 328/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 19135.0274 - val_loss: 15207.9820\n",
      "Epoch 329/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18923.7394 - val_loss: 14965.7481\n",
      "Epoch 330/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 18535.9474 - val_loss: 17499.9861\n",
      "Epoch 331/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 19013.6725 - val_loss: 15235.5978\n",
      "Epoch 332/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 18596.5386 - val_loss: 15663.1766\n",
      "Epoch 333/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 18753.9279 - val_loss: 14441.8432\n",
      "Epoch 334/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18830.9042 - val_loss: 14302.3303\n",
      "Epoch 335/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18712.8998 - val_loss: 14407.8947\n",
      "Epoch 336/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18339.9842 - val_loss: 16368.5578\n",
      "Epoch 337/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 18322.5995 - val_loss: 14554.7695\n",
      "Epoch 338/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18302.4392 - val_loss: 18285.9036\n",
      "Epoch 339/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 18712.5002 - val_loss: 16307.5702\n",
      "Epoch 340/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18290.9863 - val_loss: 14239.9206\n",
      "Epoch 341/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18704.4309 - val_loss: 14550.0324\n",
      "Epoch 342/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 18247.0918 - val_loss: 14879.0659\n",
      "Epoch 343/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 18006.7334 - val_loss: 18404.3097\n",
      "Epoch 344/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 18743.3766 - val_loss: 14351.7088\n",
      "Epoch 345/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 18354.7083 - val_loss: 13809.4760\n",
      "Epoch 346/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 18344.7377 - val_loss: 14164.0234\n",
      "Epoch 347/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 17953.9372 - val_loss: 15203.0973\n",
      "Epoch 348/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 18169.8337 - val_loss: 15557.0146\n",
      "Epoch 349/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 18846.4769 - val_loss: 13736.5097\n",
      "Epoch 350/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 18310.2781 - val_loss: 15919.4781\n",
      "Epoch 351/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17808.3110 - val_loss: 16368.7301\n",
      "Epoch 352/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18350.3996 - val_loss: 14352.2247\n",
      "Epoch 353/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 18125.6151 - val_loss: 14588.8044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17982.2255 - val_loss: 15111.4960\n",
      "Epoch 355/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 18200.9428 - val_loss: 16779.2044\n",
      "Epoch 356/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17829.2466 - val_loss: 15074.7010\n",
      "Epoch 357/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 18016.9196 - val_loss: 14864.5632\n",
      "Epoch 358/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 17915.1799 - val_loss: 24316.4935\n",
      "Epoch 359/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 19223.4313 - val_loss: 14180.9230\n",
      "Epoch 360/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 18647.8201 - val_loss: 13863.6924\n",
      "Epoch 361/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 18664.2566 - val_loss: 15385.2874\n",
      "Epoch 362/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17911.7704 - val_loss: 14680.4609\n",
      "Epoch 363/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 17927.6700 - val_loss: 14011.2587\n",
      "Epoch 364/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 17879.9066 - val_loss: 14464.9448\n",
      "Epoch 365/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 18198.5349 - val_loss: 15854.3383\n",
      "Epoch 366/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17806.2551 - val_loss: 16639.1137\n",
      "Epoch 367/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17713.9328 - val_loss: 15978.6447\n",
      "Epoch 368/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18191.1775 - val_loss: 13860.3972\n",
      "Epoch 369/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 17839.4774 - val_loss: 16243.3496\n",
      "Epoch 370/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 18056.7944 - val_loss: 13988.9696\n",
      "Epoch 371/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17830.5053 - val_loss: 13991.4631\n",
      "Epoch 372/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 17826.4593 - val_loss: 14288.8727\n",
      "Epoch 373/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 18230.0502 - val_loss: 13970.4442\n",
      "Epoch 374/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 18149.2701 - val_loss: 13912.5779\n",
      "Epoch 375/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17991.8544 - val_loss: 14408.1569\n",
      "Epoch 376/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17852.9588 - val_loss: 13976.1019\n",
      "Epoch 377/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17220.9854 - val_loss: 14601.7443\n",
      "Epoch 378/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 18052.9831 - val_loss: 14810.8670\n",
      "Epoch 379/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 17936.4085 - val_loss: 15385.9314\n",
      "Epoch 380/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17604.2571 - val_loss: 22286.7142\n",
      "Epoch 381/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 18617.3345 - val_loss: 16034.6185\n",
      "Epoch 382/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17403.8869 - val_loss: 14999.4376\n",
      "Epoch 383/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17939.8127 - val_loss: 14766.4007\n",
      "Epoch 384/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 18240.0339 - val_loss: 14057.3904\n",
      "Epoch 385/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 17869.7416 - val_loss: 17336.3759\n",
      "Epoch 386/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17826.6345 - val_loss: 15285.4909\n",
      "Epoch 387/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17667.2922 - val_loss: 14430.3984\n",
      "Epoch 388/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 17571.7256 - val_loss: 14216.6904\n",
      "Epoch 389/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 17352.5210 - val_loss: 13842.0403\n",
      "Epoch 390/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17804.1591 - val_loss: 14489.6196\n",
      "Epoch 391/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17290.5272 - val_loss: 15556.0982\n",
      "Epoch 392/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 17562.2438 - val_loss: 14057.2289\n",
      "Epoch 393/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 17475.4925 - val_loss: 14393.1716\n",
      "Epoch 394/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 17683.2711 - val_loss: 13867.6408\n",
      "Epoch 395/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 18206.1145 - val_loss: 14119.2243\n",
      "Epoch 396/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17573.8009 - val_loss: 14654.6191\n",
      "Epoch 397/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17220.1603 - val_loss: 17501.2350\n",
      "Epoch 398/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17444.1953 - val_loss: 15443.5200\n",
      "Epoch 399/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17212.9262 - val_loss: 14271.1408\n",
      "Epoch 400/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 18024.3335 - val_loss: 14294.3726\n",
      "Epoch 401/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17486.2469 - val_loss: 13969.2431\n",
      "Epoch 402/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17356.3129 - val_loss: 14932.2968\n",
      "Epoch 403/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17733.6313 - val_loss: 15349.2541\n",
      "Epoch 404/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17096.2496 - val_loss: 14960.6332\n",
      "Epoch 405/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17120.7252 - val_loss: 14787.6082\n",
      "Epoch 406/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 17491.6736 - val_loss: 19178.5432\n",
      "Epoch 407/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17724.7867 - val_loss: 14122.0443\n",
      "Epoch 408/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17579.8739 - val_loss: 14003.0985\n",
      "Epoch 409/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17608.8391 - val_loss: 17843.3101\n",
      "Epoch 410/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17523.1099 - val_loss: 14959.4707\n",
      "Epoch 411/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16910.8874 - val_loss: 13747.2737\n",
      "Epoch 412/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17539.3152 - val_loss: 14720.9098\n",
      "Epoch 413/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17267.5506 - val_loss: 14258.4516\n",
      "Epoch 414/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17315.9268 - val_loss: 13593.2258\n",
      "Epoch 415/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17380.5531 - val_loss: 14079.7826\n",
      "Epoch 416/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16996.8228 - val_loss: 15113.6179\n",
      "Epoch 417/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 17600.8175 - val_loss: 18986.0353\n",
      "Epoch 418/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17023.1818 - val_loss: 14341.5397\n",
      "Epoch 419/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17573.1886 - val_loss: 14370.9430\n",
      "Epoch 420/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17225.8739 - val_loss: 15407.3638\n",
      "Epoch 421/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17412.0493 - val_loss: 19036.0672\n",
      "Epoch 422/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17108.0607 - val_loss: 15606.9727\n",
      "Epoch 423/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17136.4948 - val_loss: 15391.9444\n",
      "Epoch 424/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17093.5108 - val_loss: 14448.2228\n",
      "Epoch 425/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16837.8037 - val_loss: 16118.2474\n",
      "Epoch 426/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17296.2004 - val_loss: 13944.9400\n",
      "Epoch 427/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17272.2626 - val_loss: 13772.1651\n",
      "Epoch 428/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17281.5558 - val_loss: 13642.4159\n",
      "Epoch 429/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 17101.2987 - val_loss: 15898.3358\n",
      "Epoch 430/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16709.3143 - val_loss: 19334.2600\n",
      "Epoch 431/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 16868.6854 - val_loss: 16250.8959\n",
      "Epoch 432/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17385.3112 - val_loss: 13705.7346\n",
      "Epoch 433/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17247.9291 - val_loss: 14623.1077\n",
      "Epoch 434/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17188.4737 - val_loss: 13852.3366\n",
      "Epoch 435/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16656.4663 - val_loss: 14797.9058\n",
      "Epoch 436/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 17156.8052 - val_loss: 13735.2475\n",
      "Epoch 437/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 17050.5127 - val_loss: 17040.0685\n",
      "Epoch 438/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16785.3803 - val_loss: 15292.6484\n",
      "Epoch 439/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16491.9697 - val_loss: 15786.6080\n",
      "Epoch 440/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17464.6337 - val_loss: 15852.0196\n",
      "Epoch 441/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17213.6505 - val_loss: 15082.6042\n",
      "Epoch 442/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 17345.8611 - val_loss: 14912.8041\n",
      "Epoch 443/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16981.0900 - val_loss: 18065.5751\n",
      "Epoch 444/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 17532.0109 - val_loss: 16386.4432\n",
      "Epoch 445/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 17591.5213 - val_loss: 14487.9600\n",
      "Epoch 446/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17624.2621 - val_loss: 16752.8077\n",
      "Epoch 447/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16998.9168 - val_loss: 13496.9836\n",
      "Epoch 448/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 16836.7056 - val_loss: 14631.2539\n",
      "Epoch 449/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16696.3389 - val_loss: 16631.2494\n",
      "Epoch 450/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 16983.9090 - val_loss: 15312.0523\n",
      "Epoch 451/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16810.2610 - val_loss: 14278.9533\n",
      "Epoch 452/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17404.3263 - val_loss: 15086.4043\n",
      "Epoch 453/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 17100.2959 - val_loss: 13936.6329\n",
      "Epoch 454/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16667.1507 - val_loss: 18293.9448\n",
      "Epoch 455/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 17168.9288- ETA: 0s - - 1s 438us/step - loss: 17086.7000 - val_loss: 13579.2260\n",
      "Epoch 456/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16701.5239 - val_loss: 14569.9128\n",
      "Epoch 457/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16879.7268 - val_loss: 13863.3398\n",
      "Epoch 458/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 16426.4349 - val_loss: 17490.6424\n",
      "Epoch 459/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 17047.0664 - val_loss: 14906.5276\n",
      "Epoch 460/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 17470.8861 - val_loss: 14052.3652\n",
      "Epoch 461/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16674.0154 - val_loss: 17727.5517\n",
      "Epoch 462/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 17145.5984 - val_loss: 14692.3786\n",
      "Epoch 463/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 17166.9755 - val_loss: 14124.9136\n",
      "Epoch 464/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16679.6169 - val_loss: 19373.4150\n",
      "Epoch 465/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 16774.5541 - val_loss: 14200.0199\n",
      "Epoch 466/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 16595.9005 - val_loss: 14423.6457\n",
      "Epoch 467/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16689.2204 - val_loss: 14240.4985\n",
      "Epoch 468/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16708.0954 - val_loss: 14334.9017\n",
      "Epoch 469/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 17191.4972 - val_loss: 13775.6621\n",
      "Epoch 470/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17505.5673 - val_loss: 13765.9852\n",
      "Epoch 471/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 17377.3753 - val_loss: 16874.4895\n",
      "Epoch 472/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16932.0075 - val_loss: 15280.1072\n",
      "Epoch 473/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16530.4014 - val_loss: 14520.9200\n",
      "Epoch 474/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17395.5364 - val_loss: 13848.9501\n",
      "Epoch 475/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16857.5059 - val_loss: 13565.6380\n",
      "Epoch 476/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 16767.7075 - val_loss: 19872.7868\n",
      "Epoch 477/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16884.9123 - val_loss: 13176.7210\n",
      "Epoch 478/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16330.7191 - val_loss: 14813.3151\n",
      "Epoch 479/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 16560.1846 - val_loss: 13560.4959\n",
      "Epoch 480/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 16994.8374 - val_loss: 13748.0220\n",
      "Epoch 481/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 17105.0768 - val_loss: 13977.5572\n",
      "Epoch 482/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 16926.7186 - val_loss: 15421.4735\n",
      "Epoch 483/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 17416.383 - 1s 442us/step - loss: 17520.7117 - val_loss: 14974.8713\n",
      "Epoch 484/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 17241.7099 - val_loss: 16109.2987\n",
      "Epoch 485/1000\n",
      "2304/2304 [==============================] - 1s 467us/step - loss: 16878.6128 - val_loss: 13340.2037\n",
      "Epoch 486/1000\n",
      "2304/2304 [==============================] - 1s 460us/step - loss: 16567.2597 - val_loss: 13226.7989\n",
      "Epoch 487/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17009.0485 - val_loss: 14334.8273\n",
      "Epoch 488/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 17224.3196 - val_loss: 15182.8221\n",
      "Epoch 489/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16113.3428 - val_loss: 14707.3002\n",
      "Epoch 490/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16157.4614 - val_loss: 17262.7748\n",
      "Epoch 491/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16754.3682 - val_loss: 17514.4146\n",
      "Epoch 492/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16435.4573 - val_loss: 13711.0666\n",
      "Epoch 493/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 17039.9159 - val_loss: 15920.7148\n",
      "Epoch 494/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304/2304 [==============================] - 1s 443us/step - loss: 16618.5890 - val_loss: 13543.7893\n",
      "Epoch 495/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 17146.2448 - val_loss: 18693.5495\n",
      "Epoch 496/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16916.5060 - val_loss: 13491.6188\n",
      "Epoch 497/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 16322.7569 - val_loss: 14055.7516\n",
      "Epoch 498/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16738.7356 - val_loss: 13729.1235\n",
      "Epoch 499/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 17037.1458 - val_loss: 19032.3017\n",
      "Epoch 500/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 17037.1399 - val_loss: 13309.6670\n",
      "Epoch 501/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 16405.3647 - val_loss: 13464.1638\n",
      "Epoch 502/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 17211.2725 - val_loss: 17083.4213\n",
      "Epoch 503/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 17172.4802 - val_loss: 13478.5523\n",
      "Epoch 504/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16247.5303 - val_loss: 14198.8873\n",
      "Epoch 505/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16671.5918 - val_loss: 13535.8521\n",
      "Epoch 506/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16185.6086 - val_loss: 14095.6265\n",
      "Epoch 507/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16207.7347 - val_loss: 14325.4418\n",
      "Epoch 508/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 16652.1647 - val_loss: 14851.3673\n",
      "Epoch 509/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 16606.8829 - val_loss: 14483.6561\n",
      "Epoch 510/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 16154.6917 - val_loss: 13027.8321\n",
      "Epoch 511/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 16352.7531 - val_loss: 13074.6578\n",
      "Epoch 512/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 16269.5398 - val_loss: 15614.6946\n",
      "Epoch 513/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16844.1695 - val_loss: 13532.4958\n",
      "Epoch 514/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16391.5720 - val_loss: 13839.0900\n",
      "Epoch 515/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16910.4774 - val_loss: 13006.5320\n",
      "Epoch 516/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16441.9044 - val_loss: 13741.3823\n",
      "Epoch 517/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16175.2031 - val_loss: 13118.6830\n",
      "Epoch 518/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16029.5415 - val_loss: 13535.7123\n",
      "Epoch 519/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 16822.5800 - val_loss: 12918.1999\n",
      "Epoch 520/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16400.1417 - val_loss: 13436.6186\n",
      "Epoch 521/1000\n",
      "2304/2304 [==============================] - 1s 471us/step - loss: 16581.6498 - val_loss: 13149.8857\n",
      "Epoch 522/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16398.8991 - val_loss: 13370.1782\n",
      "Epoch 523/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16296.1482 - val_loss: 16340.5884\n",
      "Epoch 524/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16327.9647 - val_loss: 13298.2406\n",
      "Epoch 525/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16280.1426 - val_loss: 13291.0479\n",
      "Epoch 526/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 16098.8848 - val_loss: 13626.7445\n",
      "Epoch 527/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16265.7438 - val_loss: 13826.5380\n",
      "Epoch 528/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15989.9011 - val_loss: 14713.3395\n",
      "Epoch 529/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15569.1148 - val_loss: 13209.5831\n",
      "Epoch 530/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16541.1532 - val_loss: 17341.2461\n",
      "Epoch 531/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16239.2389 - val_loss: 13829.2114\n",
      "Epoch 532/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16521.4224 - val_loss: 15856.1819\n",
      "Epoch 533/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15968.5748 - val_loss: 12955.7784\n",
      "Epoch 534/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 16293.7703 - val_loss: 13159.6920\n",
      "Epoch 535/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15915.4719 - val_loss: 15236.5337\n",
      "Epoch 536/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16546.5183 - val_loss: 16853.1425\n",
      "Epoch 537/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16415.3709 - val_loss: 22590.1958\n",
      "Epoch 538/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 16038.1731 - val_loss: 15478.0320\n",
      "Epoch 539/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16662.2867 - val_loss: 13633.4050\n",
      "Epoch 540/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16813.9251 - val_loss: 12660.4432\n",
      "Epoch 541/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 16527.9992 - val_loss: 14913.9604\n",
      "Epoch 542/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 16079.3291 - val_loss: 13788.1918\n",
      "Epoch 543/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16225.2902 - val_loss: 14426.3797\n",
      "Epoch 544/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 15732.6024 - val_loss: 13636.5850\n",
      "Epoch 545/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16214.2543 - val_loss: 21259.3888\n",
      "Epoch 546/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 16336.5275 - val_loss: 13642.9841\n",
      "Epoch 547/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16242.7494 - val_loss: 12891.3443\n",
      "Epoch 548/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15609.3064 - val_loss: 15241.3289\n",
      "Epoch 549/1000\n",
      "2304/2304 [==============================] - 1s 454us/step - loss: 16055.6001 - val_loss: 15129.6870\n",
      "Epoch 550/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 16056.1482 - val_loss: 13194.1173\n",
      "Epoch 551/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16373.1419 - val_loss: 13835.9007\n",
      "Epoch 552/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 16585.9757 - val_loss: 15642.5804\n",
      "Epoch 553/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 16268.6899 - val_loss: 12619.5854\n",
      "Epoch 554/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16432.3227 - val_loss: 14910.7167\n",
      "Epoch 555/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15964.3666 - val_loss: 13346.9381\n",
      "Epoch 556/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15907.5030 - val_loss: 12983.0486\n",
      "Epoch 557/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15918.8584 - val_loss: 13650.5844\n",
      "Epoch 558/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16200.4612 - val_loss: 12951.2539\n",
      "Epoch 559/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15835.6661 - val_loss: 14813.2323\n",
      "Epoch 560/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 16570.0578 - val_loss: 14454.0631\n",
      "Epoch 561/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16869.6169 - val_loss: 13610.7718\n",
      "Epoch 562/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16840.4261 - val_loss: 13181.9136\n",
      "Epoch 563/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15979.8033 - val_loss: 13446.4118\n",
      "Epoch 564/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15563.6671 - val_loss: 13199.9821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 565/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15908.4225 - val_loss: 15984.1726\n",
      "Epoch 566/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16004.9399 - val_loss: 13905.7834\n",
      "Epoch 567/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 16389.2974 - val_loss: 13452.7645\n",
      "Epoch 568/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15584.9971 - val_loss: 14775.5267\n",
      "Epoch 569/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15664.2811 - val_loss: 13648.0294\n",
      "Epoch 570/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 16375.2549 - val_loss: 13240.0203\n",
      "Epoch 571/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15903.5278 - val_loss: 14575.3229\n",
      "Epoch 572/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16540.2915 - val_loss: 12986.2193\n",
      "Epoch 573/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15546.8738 - val_loss: 12724.5387\n",
      "Epoch 574/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15573.6981 - val_loss: 14370.9492\n",
      "Epoch 575/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15998.9777 - val_loss: 14381.9216\n",
      "Epoch 576/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 16236.6067 - val_loss: 13139.3926\n",
      "Epoch 577/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 16401.3169 - val_loss: 12909.4291\n",
      "Epoch 578/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 15951.6085 - val_loss: 13372.4539\n",
      "Epoch 579/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15390.301 - 1s 447us/step - loss: 15447.2109 - val_loss: 16080.7027\n",
      "Epoch 580/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15932.6666 - val_loss: 13824.2292\n",
      "Epoch 581/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15664.1162 - val_loss: 14778.0713\n",
      "Epoch 582/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15933.7029 - val_loss: 13003.9517\n",
      "Epoch 583/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15956.3189 - val_loss: 16177.6614\n",
      "Epoch 584/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15874.3583 - val_loss: 13080.2921\n",
      "Epoch 585/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16791.4277 - val_loss: 14088.6852\n",
      "Epoch 586/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15705.0799 - val_loss: 18454.0310\n",
      "Epoch 587/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15808.1309 - val_loss: 16820.5833\n",
      "Epoch 588/1000\n",
      "2304/2304 [==============================] - 1s 464us/step - loss: 16183.8922 - val_loss: 14711.2256\n",
      "Epoch 589/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15707.8248 - val_loss: 13111.5689\n",
      "Epoch 590/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 16598.3475 - val_loss: 15295.8216\n",
      "Epoch 591/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15327.5790 - val_loss: 13901.1989\n",
      "Epoch 592/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15704.7646 - val_loss: 13032.4837\n",
      "Epoch 593/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15951.6286 - val_loss: 13004.5162\n",
      "Epoch 594/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 15690.0711 - val_loss: 12766.9858\n",
      "Epoch 595/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15764.8322 - val_loss: 14098.1799\n",
      "Epoch 596/1000\n",
      "2304/2304 [==============================] - 1s 450us/step - loss: 16039.9761 - val_loss: 14123.3657\n",
      "Epoch 597/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16197.0552 - val_loss: 13257.4783\n",
      "Epoch 598/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15653.8917 - val_loss: 13044.1128\n",
      "Epoch 599/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 16027.9724 - val_loss: 14400.0111\n",
      "Epoch 600/1000\n",
      "2304/2304 [==============================] - 1s 463us/step - loss: 15569.4053 - val_loss: 14585.1445\n",
      "Epoch 601/1000\n",
      "2304/2304 [==============================] - 1s 453us/step - loss: 16236.5629 - val_loss: 14213.7991\n",
      "Epoch 602/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15410.8726 - val_loss: 13744.9428\n",
      "Epoch 603/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15623.0107 - val_loss: 13769.4555\n",
      "Epoch 604/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15422.4580 - val_loss: 13720.9273\n",
      "Epoch 605/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15629.3536 - val_loss: 13780.4440\n",
      "Epoch 606/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15512.328 - 1s 449us/step - loss: 15667.5894 - val_loss: 15107.2038\n",
      "Epoch 607/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15842.8541 - val_loss: 15396.6564\n",
      "Epoch 608/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16343.3226 - val_loss: 16418.3831\n",
      "Epoch 609/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15627.2895 - val_loss: 13080.5057\n",
      "Epoch 610/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 16138.2899 - val_loss: 13839.8605\n",
      "Epoch 611/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15795.7646 - val_loss: 14323.5030\n",
      "Epoch 612/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 16000.4406 - val_loss: 14379.4820\n",
      "Epoch 613/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15908.1178 - val_loss: 12850.5682\n",
      "Epoch 614/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 16145.5608 - val_loss: 13584.1879\n",
      "Epoch 615/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15431.5824 - val_loss: 13392.1331\n",
      "Epoch 616/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 16703.4658 - val_loss: 14792.3624\n",
      "Epoch 617/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15772.0554 - val_loss: 15436.8464\n",
      "Epoch 618/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15374.9280 - val_loss: 13229.2396\n",
      "Epoch 619/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15145.3295 - val_loss: 14809.5443\n",
      "Epoch 620/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15543.2908 - val_loss: 16547.6276\n",
      "Epoch 621/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15959.9643 - val_loss: 16376.9515\n",
      "Epoch 622/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15781.9054 - val_loss: 15017.2809\n",
      "Epoch 623/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15574.1608 - val_loss: 12977.8039\n",
      "Epoch 624/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15664.0746 - val_loss: 16512.8301\n",
      "Epoch 625/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15434.6600 - val_loss: 13110.2442\n",
      "Epoch 626/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15833.0265 - val_loss: 13771.7392\n",
      "Epoch 627/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15141.2832 - val_loss: 12895.8720\n",
      "Epoch 628/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15806.2560 - val_loss: 12599.8844\n",
      "Epoch 629/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 15253.5951 - val_loss: 15702.9138\n",
      "Epoch 630/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 16220.005 - 1s 446us/step - loss: 16211.7160 - val_loss: 13587.7423\n",
      "Epoch 631/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15374.0106 - val_loss: 16109.5302\n",
      "Epoch 632/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15973.8315 - val_loss: 14559.4370\n",
      "Epoch 633/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15757.8239 - val_loss: 14605.0098\n",
      "Epoch 634/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15382.4610 - val_loss: 15446.6752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 635/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15981.6069 - val_loss: 14574.5966\n",
      "Epoch 636/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15255.1359 - val_loss: 16051.3238\n",
      "Epoch 637/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15448.6940 - val_loss: 13010.1859\n",
      "Epoch 638/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15537.2544 - val_loss: 14263.5028\n",
      "Epoch 639/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15717.0864 - val_loss: 13682.7131\n",
      "Epoch 640/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15358.8598 - val_loss: 13410.3975\n",
      "Epoch 641/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15642.4729 - val_loss: 13778.9329\n",
      "Epoch 642/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 16350.4903 - val_loss: 21586.3186\n",
      "Epoch 643/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15697.2444 - val_loss: 13705.7611\n",
      "Epoch 644/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15046.5153 - val_loss: 16719.6757\n",
      "Epoch 645/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15784.5210 - val_loss: 13796.9106\n",
      "Epoch 646/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15669.4205 - val_loss: 12644.5263\n",
      "Epoch 647/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15642.5598 - val_loss: 13163.1053\n",
      "Epoch 648/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15469.4455 - val_loss: 14157.4993\n",
      "Epoch 649/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 15148.3762 - val_loss: 12870.2361\n",
      "Epoch 650/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15614.2960 - val_loss: 12830.4788\n",
      "Epoch 651/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15455.5890 - val_loss: 14309.9376\n",
      "Epoch 652/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15504.0487 - val_loss: 12620.4909\n",
      "Epoch 653/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15521.0770 - val_loss: 13617.4397\n",
      "Epoch 654/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15487.8799 - val_loss: 13259.1685\n",
      "Epoch 655/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15204.8147 - val_loss: 13958.5722\n",
      "Epoch 656/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15702.2916 - val_loss: 13165.9372\n",
      "Epoch 657/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15200.5446 - val_loss: 14146.9903\n",
      "Epoch 658/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 15479.8287 - val_loss: 13355.3974\n",
      "Epoch 659/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15440.6843 - val_loss: 13331.1294\n",
      "Epoch 660/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 15174.4019 - val_loss: 12858.8573\n",
      "Epoch 661/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15110.9219 - val_loss: 12799.9921\n",
      "Epoch 662/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15598.324 - 1s 448us/step - loss: 15515.2419 - val_loss: 12942.6975\n",
      "Epoch 663/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 16275.1000 - val_loss: 16717.4047\n",
      "Epoch 664/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 16169.6125 - val_loss: 12684.8459\n",
      "Epoch 665/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15119.5771 - val_loss: 17778.7259\n",
      "Epoch 666/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15477.4023 - val_loss: 13685.2982\n",
      "Epoch 667/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15982.5753 - val_loss: 14503.3253\n",
      "Epoch 668/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15682.8486 - val_loss: 15272.2460\n",
      "Epoch 669/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15223.0342 - val_loss: 12861.6631\n",
      "Epoch 670/1000\n",
      "2304/2304 [==============================] - 1s 458us/step - loss: 15199.3037 - val_loss: 12720.9584\n",
      "Epoch 671/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15367.5364 - val_loss: 12661.7466\n",
      "Epoch 672/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15171.9637 - val_loss: 13398.3861\n",
      "Epoch 673/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15272.5848 - val_loss: 13891.8174\n",
      "Epoch 674/1000\n",
      "2304/2304 [==============================] - 1s 457us/step - loss: 15364.4168 - val_loss: 13129.6698\n",
      "Epoch 675/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15352.5513 - val_loss: 13137.0173\n",
      "Epoch 676/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15420.8494 - val_loss: 14306.8728\n",
      "Epoch 677/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15816.9606 - val_loss: 13225.2205\n",
      "Epoch 678/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15520.9441 - val_loss: 12961.2857\n",
      "Epoch 679/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 16166.1388 - val_loss: 13093.5504\n",
      "Epoch 680/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15809.7020 - val_loss: 12755.8231\n",
      "Epoch 681/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15275.4096 - val_loss: 14574.4372\n",
      "Epoch 682/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15262.1467 - val_loss: 15008.6220\n",
      "Epoch 683/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15541.8515 - val_loss: 12507.0198\n",
      "Epoch 684/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 15458.2967 - val_loss: 12919.8445\n",
      "Epoch 685/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15089.8102 - val_loss: 13483.9403\n",
      "Epoch 686/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15078.7916 - val_loss: 13308.9251\n",
      "Epoch 687/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14969.1277 - val_loss: 15465.7025\n",
      "Epoch 688/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15335.7592 - val_loss: 12952.5697\n",
      "Epoch 689/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15527.9751 - val_loss: 17052.4783\n",
      "Epoch 690/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15339.5878 - val_loss: 14415.3618\n",
      "Epoch 691/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15469.8665 - val_loss: 14247.9914\n",
      "Epoch 692/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15702.3830 - val_loss: 17907.0751\n",
      "Epoch 693/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 15765.4085 - val_loss: 13254.7512\n",
      "Epoch 694/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15332.0656 - val_loss: 18456.6299\n",
      "Epoch 695/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15447.8551 - val_loss: 12613.2257\n",
      "Epoch 696/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14687.8422 - val_loss: 13083.2457\n",
      "Epoch 697/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15330.3883 - val_loss: 18014.6404\n",
      "Epoch 698/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15781.9598 - val_loss: 16162.5326\n",
      "Epoch 699/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15493.8309 - val_loss: 17285.5977\n",
      "Epoch 700/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 15423.0763 - val_loss: 12625.9207\n",
      "Epoch 701/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15297.0811 - val_loss: 13373.4003\n",
      "Epoch 702/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15426.0078 - val_loss: 13488.4394\n",
      "Epoch 703/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15466.9557 - val_loss: 14845.1572\n",
      "Epoch 704/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15065.8811 - val_loss: 12732.2395\n",
      "Epoch 705/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15026.7516 - val_loss: 13223.4333\n",
      "Epoch 706/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15230.2854 - val_loss: 14756.2749\n",
      "Epoch 707/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15406.9381 - val_loss: 13308.5025\n",
      "Epoch 708/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15260.3629 - val_loss: 18116.0258\n",
      "Epoch 709/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15283.3038 - val_loss: 13337.3922\n",
      "Epoch 710/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15137.5314 - val_loss: 13265.3038\n",
      "Epoch 711/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15759.4561 - val_loss: 14528.8233\n",
      "Epoch 712/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15241.5850 - val_loss: 12762.3783\n",
      "Epoch 713/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14968.4679 - val_loss: 13901.8424\n",
      "Epoch 714/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 15471.8470 - val_loss: 13121.6925\n",
      "Epoch 715/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15340.8782 - val_loss: 16421.3447\n",
      "Epoch 716/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15203.0577 - val_loss: 13425.4123\n",
      "Epoch 717/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15364.1613 - val_loss: 14678.5288\n",
      "Epoch 718/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15190.8276 - val_loss: 13293.1317\n",
      "Epoch 719/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15485.2657 - val_loss: 16684.7799\n",
      "Epoch 720/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 16062.7201 - val_loss: 12756.5438\n",
      "Epoch 721/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15582.1366 - val_loss: 13934.6589\n",
      "Epoch 722/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 14930.4560 - val_loss: 14532.9120\n",
      "Epoch 723/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15068.7575 - val_loss: 12634.7672\n",
      "Epoch 724/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15363.4014 - val_loss: 13434.6976\n",
      "Epoch 725/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15257.4327 - val_loss: 18779.9918\n",
      "Epoch 726/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15877.7786 - val_loss: 13005.0797\n",
      "Epoch 727/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15261.8529 - val_loss: 12943.7489\n",
      "Epoch 728/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 15631.8654 - val_loss: 12685.7935\n",
      "Epoch 729/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15082.9631 - val_loss: 12853.9259\n",
      "Epoch 730/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14789.6620 - val_loss: 13291.1079\n",
      "Epoch 731/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14779.1322 - val_loss: 12923.7221\n",
      "Epoch 732/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 14957.5461 - val_loss: 14639.1517\n",
      "Epoch 733/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15424.5130 - val_loss: 12906.5334\n",
      "Epoch 734/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 15092.7149 - val_loss: 12938.7308\n",
      "Epoch 735/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14993.9403 - val_loss: 13545.9049\n",
      "Epoch 736/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 14567.7017 - val_loss: 13553.1889\n",
      "Epoch 737/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 15193.0467 - val_loss: 16555.1944\n",
      "Epoch 738/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15208.2199 - val_loss: 13473.8713\n",
      "Epoch 739/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15558.0719 - val_loss: 13306.9156\n",
      "Epoch 740/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15205.8590 - val_loss: 13603.1274\n",
      "Epoch 741/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 14711.1822 - val_loss: 17975.5598\n",
      "Epoch 742/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 15439.0352 - val_loss: 18252.7317\n",
      "Epoch 743/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14858.0257 - val_loss: 13080.7335\n",
      "Epoch 744/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15334.4735 - val_loss: 12367.6314\n",
      "Epoch 745/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 15592.4208 - val_loss: 12456.6742\n",
      "Epoch 746/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 15372.3296 - val_loss: 13681.8867\n",
      "Epoch 747/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15552.5056 - val_loss: 13359.9924\n",
      "Epoch 748/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15025.2245 - val_loss: 13198.7190\n",
      "Epoch 749/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 15587.6711 - val_loss: 13291.3897\n",
      "Epoch 750/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15234.3599 - val_loss: 13104.8654\n",
      "Epoch 751/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 15286.4515 - val_loss: 13389.0263\n",
      "Epoch 752/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 15011.1919 - val_loss: 13671.0663\n",
      "Epoch 753/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 14678.4676 - val_loss: 13171.7875\n",
      "Epoch 754/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 14898.6622 - val_loss: 16745.6186\n",
      "Epoch 755/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14864.0150 - val_loss: 14502.9875\n",
      "Epoch 756/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 14996.6706 - val_loss: 14170.1225\n",
      "Epoch 757/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14958.4556 - val_loss: 13103.1940\n",
      "Epoch 758/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14827.0645 - val_loss: 12728.4479\n",
      "Epoch 759/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15163.0861 - val_loss: 13287.7952\n",
      "Epoch 760/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14740.0526 - val_loss: 12897.9880\n",
      "Epoch 761/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 14966.5553 - val_loss: 13621.3832\n",
      "Epoch 762/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14799.1578 - val_loss: 14286.3744\n",
      "Epoch 763/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14436.9415 - val_loss: 13498.1127\n",
      "Epoch 764/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15144.7726 - val_loss: 12865.2890\n",
      "Epoch 765/1000\n",
      "2304/2304 [==============================] - 1s 447us/step - loss: 15369.3907 - val_loss: 13159.7846\n",
      "Epoch 766/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 14932.8306 - val_loss: 13319.9050\n",
      "Epoch 767/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14700.5915 - val_loss: 12496.0247\n",
      "Epoch 768/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 14422.4766 - val_loss: 12903.3622\n",
      "Epoch 769/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 14772.8422 - val_loss: 12729.0690\n",
      "Epoch 770/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 15411.607 - 1s 442us/step - loss: 15346.0232 - val_loss: 14042.6256\n",
      "Epoch 771/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15231.9011 - val_loss: 13969.7030\n",
      "Epoch 772/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 15155.9134 - val_loss: 14454.8772\n",
      "Epoch 773/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 15267.4308 - val_loss: 13259.2004\n",
      "Epoch 774/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14596.1594 - val_loss: 13166.8524\n",
      "Epoch 775/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304/2304 [==============================] - 1s 420us/step - loss: 14974.0176 - val_loss: 15539.5823\n",
      "Epoch 776/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15169.9119 - val_loss: 13228.7943\n",
      "Epoch 777/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14630.1758 - val_loss: 13663.6288\n",
      "Epoch 778/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 14674.2638 - val_loss: 12558.5938\n",
      "Epoch 779/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14920.9787 - val_loss: 13532.3238\n",
      "Epoch 780/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 15182.5596 - val_loss: 15951.0021\n",
      "Epoch 781/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14665.4194 - val_loss: 12908.2029\n",
      "Epoch 782/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14690.0533 - val_loss: 14167.9302\n",
      "Epoch 783/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14653.5695 - val_loss: 17030.5262\n",
      "Epoch 784/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 15122.4909 - val_loss: 12568.5641\n",
      "Epoch 785/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 15265.6583 - val_loss: 12658.0560\n",
      "Epoch 786/1000\n",
      "2304/2304 [==============================] - 1s 461us/step - loss: 14948.2878 - val_loss: 13892.8752\n",
      "Epoch 787/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14933.4436 - val_loss: 14457.1670\n",
      "Epoch 788/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 15085.2040 - val_loss: 13747.4289\n",
      "Epoch 789/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 15379.0492 - val_loss: 19403.6576\n",
      "Epoch 790/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 15351.0965 - val_loss: 15456.3321\n",
      "Epoch 791/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 14805.4371 - val_loss: 12852.0827\n",
      "Epoch 792/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 14794.1490 - val_loss: 12984.7817\n",
      "Epoch 793/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 14434.4702 - val_loss: 12845.6965\n",
      "Epoch 794/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 14672.0893 - val_loss: 13594.8156\n",
      "Epoch 795/1000\n",
      "2304/2304 [==============================] - 1s 452us/step - loss: 14665.5351 - val_loss: 13367.0068\n",
      "Epoch 796/1000\n",
      "2304/2304 [==============================] - 1s 442us/step - loss: 14691.3304 - val_loss: 12902.3428\n",
      "Epoch 797/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 15322.3794 - val_loss: 13206.3453\n",
      "Epoch 798/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14591.8013 - val_loss: 12691.5457\n",
      "Epoch 799/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14238.9320 - val_loss: 12883.0565\n",
      "Epoch 800/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14562.4019 - val_loss: 13239.7346\n",
      "Epoch 801/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14895.1009 - val_loss: 12925.1134\n",
      "Epoch 802/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14640.8927 - val_loss: 12759.0829\n",
      "Epoch 803/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14646.1457 - val_loss: 12718.9311\n",
      "Epoch 804/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14635.7928 - val_loss: 12636.7899\n",
      "Epoch 805/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 13996.3517 - val_loss: 14381.3851\n",
      "Epoch 806/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14318.8125 - val_loss: 15468.8791\n",
      "Epoch 807/1000\n",
      "2304/2304 [==============================] - 1s 443us/step - loss: 14880.0421 - val_loss: 13126.8431\n",
      "Epoch 808/1000\n",
      "2304/2304 [==============================] - 1s 451us/step - loss: 15080.8034 - val_loss: 14136.3962\n",
      "Epoch 809/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15469.5417 - val_loss: 12694.9700\n",
      "Epoch 810/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 14256.0116 - val_loss: 12779.1585\n",
      "Epoch 811/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 15062.1193 - val_loss: 13845.3082\n",
      "Epoch 812/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14080.0018 - val_loss: 13449.0193\n",
      "Epoch 813/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14612.0249 - val_loss: 13226.6961\n",
      "Epoch 814/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14793.5876 - val_loss: 12672.4397\n",
      "Epoch 815/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14473.2528 - val_loss: 12693.7991\n",
      "Epoch 816/1000\n",
      "2304/2304 [==============================] - 1s 456us/step - loss: 14533.8183 - val_loss: 13692.2471\n",
      "Epoch 817/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14729.4543 - val_loss: 13083.3531\n",
      "Epoch 818/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14497.7936 - val_loss: 13903.4400\n",
      "Epoch 819/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14109.7411 - val_loss: 13386.7339\n",
      "Epoch 820/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14994.6687 - val_loss: 14384.5567\n",
      "Epoch 821/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14667.1439 - val_loss: 16717.5792\n",
      "Epoch 822/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 15194.1799 - val_loss: 12673.5339\n",
      "Epoch 823/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14383.1840 - val_loss: 13179.6093\n",
      "Epoch 824/1000\n",
      "2304/2304 [==============================] - 1s 448us/step - loss: 14762.0785 - val_loss: 12920.0712\n",
      "Epoch 825/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14621.4354 - val_loss: 13191.5815\n",
      "Epoch 826/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 14784.9669 - val_loss: 12863.7764\n",
      "Epoch 827/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14490.9969 - val_loss: 12752.3748\n",
      "Epoch 828/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14351.1834 - val_loss: 12576.6446\n",
      "Epoch 829/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 15036.8720 - val_loss: 12418.5804\n",
      "Epoch 830/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14464.0178 - val_loss: 12871.3090\n",
      "Epoch 831/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 14654.7483 - val_loss: 13201.5221\n",
      "Epoch 832/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14462.2237 - val_loss: 13925.0163\n",
      "Epoch 833/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 14949.5650 - val_loss: 13039.8272\n",
      "Epoch 834/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14270.4275 - val_loss: 12572.5281\n",
      "Epoch 835/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14900.3856 - val_loss: 12620.9649\n",
      "Epoch 836/1000\n",
      "2304/2304 [==============================] - 1s 409us/step - loss: 14709.6670 - val_loss: 12989.1388\n",
      "Epoch 837/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14657.4319 - val_loss: 13228.2369\n",
      "Epoch 838/1000\n",
      "2304/2304 [==============================] - 1s 472us/step - loss: 14724.9100 - val_loss: 12757.6617\n",
      "Epoch 839/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 14601.4974 - val_loss: 12417.1430\n",
      "Epoch 840/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14986.3101 - val_loss: 17222.0426\n",
      "Epoch 841/1000\n",
      "2304/2304 [==============================] - 1s 411us/step - loss: 15089.0709 - val_loss: 12555.9500\n",
      "Epoch 842/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14993.7458 - val_loss: 14066.9829\n",
      "Epoch 843/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 14532.6220 - val_loss: 18880.1531\n",
      "Epoch 844/1000\n",
      "2304/2304 [==============================] - 1s 415us/step - loss: 14584.9105 - val_loss: 13635.9832\n",
      "Epoch 845/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14396.5144 - val_loss: 12778.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 846/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14060.4311 - val_loss: 13225.5006\n",
      "Epoch 847/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14654.3758 - val_loss: 13023.3650\n",
      "Epoch 848/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14654.8375 - val_loss: 13103.5657\n",
      "Epoch 849/1000\n",
      "2304/2304 [==============================] - 1s 431us/step - loss: 14830.6239 - val_loss: 13058.2414\n",
      "Epoch 850/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14764.2105 - val_loss: 13815.4281\n",
      "Epoch 851/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14613.9552 - val_loss: 13237.9735\n",
      "Epoch 852/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14611.7756 - val_loss: 13520.5362\n",
      "Epoch 853/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14431.8364 - val_loss: 13894.3668\n",
      "Epoch 854/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 15137.1521 - val_loss: 22284.5248\n",
      "Epoch 855/1000\n",
      "2304/2304 [==============================] - 1s 432us/step - loss: 14813.4715 - val_loss: 13260.7255\n",
      "Epoch 856/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14475.8784 - val_loss: 13210.7836\n",
      "Epoch 857/1000\n",
      "2304/2304 [==============================] - 1s 427us/step - loss: 14933.4577 - val_loss: 12749.1952\n",
      "Epoch 858/1000\n",
      "2304/2304 [==============================] - 1s 412us/step - loss: 14291.2518 - val_loss: 14971.0328\n",
      "Epoch 859/1000\n",
      "2304/2304 [==============================] - 1s 441us/step - loss: 15208.3715 - val_loss: 15258.7614\n",
      "Epoch 860/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 14987.8951 - val_loss: 13586.2548\n",
      "Epoch 861/1000\n",
      "2304/2304 [==============================] - 1s 430us/step - loss: 14492.0720 - val_loss: 17675.6073\n",
      "Epoch 862/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 14506.5116 - val_loss: 12518.2817\n",
      "Epoch 863/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14188.5038 - val_loss: 13342.0729\n",
      "Epoch 864/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 15359.8370 - val_loss: 16495.8379\n",
      "Epoch 865/1000\n",
      "2304/2304 [==============================] - 1s 435us/step - loss: 14965.1403 - val_loss: 13083.3793\n",
      "Epoch 866/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 14175.7473 - val_loss: 13919.3206\n",
      "Epoch 867/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14389.9764 - val_loss: 13285.3221\n",
      "Epoch 868/1000\n",
      "2304/2304 [==============================] - 1s 439us/step - loss: 14221.4755 - val_loss: 16674.3418\n",
      "Epoch 869/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 13982.3276 - val_loss: 14725.3013\n",
      "Epoch 870/1000\n",
      "2304/2304 [==============================] - 1s 370us/step - loss: 14150.5493 - val_loss: 12991.6504\n",
      "Epoch 871/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 14241.1971 - val_loss: 14242.6713\n",
      "Epoch 872/1000\n",
      "2304/2304 [==============================] - 1s 372us/step - loss: 14235.1650 - val_loss: 13106.2846\n",
      "Epoch 873/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 14888.9844 - val_loss: 13805.2642\n",
      "Epoch 874/1000\n",
      "2304/2304 [==============================] - 1s 380us/step - loss: 14627.0407 - val_loss: 13571.2920\n",
      "Epoch 875/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 14100.9699 - val_loss: 13488.7944\n",
      "Epoch 876/1000\n",
      "2304/2304 [==============================] - 1s 428us/step - loss: 14497.7654 - val_loss: 12479.8602\n",
      "Epoch 877/1000\n",
      "2304/2304 [==============================] - 1s 449us/step - loss: 14594.8237 - val_loss: 12449.0825\n",
      "Epoch 878/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14203.2660 - val_loss: 12609.4652\n",
      "Epoch 879/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 14727.8350 - val_loss: 12740.9682\n",
      "Epoch 880/1000\n",
      "2304/2304 [==============================] - 1s 438us/step - loss: 14200.1342 - val_loss: 12994.0223\n",
      "Epoch 881/1000\n",
      "2304/2304 [==============================] - 1s 425us/step - loss: 14441.8817 - val_loss: 16508.9571\n",
      "Epoch 882/1000\n",
      "2304/2304 [==============================] - 1s 444us/step - loss: 14590.5564 - val_loss: 12704.1016\n",
      "Epoch 883/1000\n",
      "2304/2304 [==============================] - 1s 437us/step - loss: 14141.6053 - val_loss: 14625.2396\n",
      "Epoch 884/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14457.2792 - val_loss: 13181.9282\n",
      "Epoch 885/1000\n",
      "2304/2304 [==============================] - 1s 395us/step - loss: 14154.0893 - val_loss: 13142.0646\n",
      "Epoch 886/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14099.0075 - val_loss: 12615.8368\n",
      "Epoch 887/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14432.0832 - val_loss: 13688.7647\n",
      "Epoch 888/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14763.6511 - val_loss: 12546.1383\n",
      "Epoch 889/1000\n",
      "2304/2304 [==============================] - 1s 400us/step - loss: 14257.1427 - val_loss: 15314.1020\n",
      "Epoch 890/1000\n",
      "2304/2304 [==============================] - 1s 407us/step - loss: 14685.3420 - val_loss: 12802.6904\n",
      "Epoch 891/1000\n",
      "2304/2304 [==============================] - 1s 398us/step - loss: 14311.2269 - val_loss: 13009.1204\n",
      "Epoch 892/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14441.2347 - val_loss: 13246.5764\n",
      "Epoch 893/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 13962.6542 - val_loss: 13388.3987\n",
      "Epoch 894/1000\n",
      "2304/2304 [==============================] - 1s 403us/step - loss: 14644.0992 - val_loss: 16022.9132\n",
      "Epoch 895/1000\n",
      "2304/2304 [==============================] - 1s 408us/step - loss: 14487.1708 - val_loss: 13156.4069\n",
      "Epoch 896/1000\n",
      "2304/2304 [==============================] - 1s 422us/step - loss: 14494.2526 - val_loss: 12960.4321\n",
      "Epoch 897/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14206.2011 - val_loss: 13049.3552\n",
      "Epoch 898/1000\n",
      "2304/2304 [==============================] - 1s 408us/step - loss: 14461.0843 - val_loss: 13081.9360\n",
      "Epoch 899/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14231.0203 - val_loss: 12909.8227\n",
      "Epoch 900/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14248.6927 - val_loss: 15215.5780\n",
      "Epoch 901/1000\n",
      "2304/2304 [==============================] - 1s 436us/step - loss: 14475.0888 - val_loss: 12317.9968\n",
      "Epoch 902/1000\n",
      "2304/2304 [==============================] - 1s 424us/step - loss: 14409.6735 - val_loss: 12467.8517\n",
      "Epoch 903/1000\n",
      "2304/2304 [==============================] - 1s 434us/step - loss: 14274.7537 - val_loss: 13747.5079\n",
      "Epoch 904/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14452.9215 - val_loss: 12402.7182\n",
      "Epoch 905/1000\n",
      "2304/2304 [==============================] - 1s 410us/step - loss: 14406.0842 - val_loss: 13519.5157\n",
      "Epoch 906/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14147.5470 - val_loss: 15100.2449\n",
      "Epoch 907/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 14430.0315 - val_loss: 13061.8966\n",
      "Epoch 908/1000\n",
      "2304/2304 [==============================] - 1s 392us/step - loss: 14037.1031 - val_loss: 15047.8518\n",
      "Epoch 909/1000\n",
      "2304/2304 [==============================] - 1s 404us/step - loss: 14497.5600 - val_loss: 12198.8537\n",
      "Epoch 910/1000\n",
      "2304/2304 [==============================] - 1s 411us/step - loss: 14366.8323 - val_loss: 14644.8727\n",
      "Epoch 911/1000\n",
      "2304/2304 [==============================] - 1s 408us/step - loss: 14138.7617 - val_loss: 13198.3730\n",
      "Epoch 912/1000\n",
      "2304/2304 [==============================] - 1s 387us/step - loss: 14551.6633 - val_loss: 12640.6007\n",
      "Epoch 913/1000\n",
      "2304/2304 [==============================] - 1s 395us/step - loss: 13842.8162 - val_loss: 13103.7514\n",
      "Epoch 914/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 14027.096 - 1s 406us/step - loss: 14014.5653 - val_loss: 13519.0226\n",
      "Epoch 915/1000\n",
      "2304/2304 [==============================] - 1s 406us/step - loss: 14198.5005 - val_loss: 13368.7286\n",
      "Epoch 916/1000\n",
      "2304/2304 [==============================] - 1s 399us/step - loss: 14822.5560 - val_loss: 15374.5320\n",
      "Epoch 917/1000\n",
      "2304/2304 [==============================] - 1s 402us/step - loss: 14289.0921 - val_loss: 14090.4929\n",
      "Epoch 918/1000\n",
      "2304/2304 [==============================] - 1s 414us/step - loss: 14206.7270 - val_loss: 13044.4802\n",
      "Epoch 919/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14460.7795 - val_loss: 13302.6180\n",
      "Epoch 920/1000\n",
      "2304/2304 [==============================] - 1s 433us/step - loss: 14155.9907 - val_loss: 13949.3602\n",
      "Epoch 921/1000\n",
      "2304/2304 [==============================] - 1s 446us/step - loss: 14249.6631 - val_loss: 13610.0707\n",
      "Epoch 922/1000\n",
      "2304/2304 [==============================] - 1s 423us/step - loss: 13840.5041 - val_loss: 13909.9199\n",
      "Epoch 923/1000\n",
      "2304/2304 [==============================] - 1s 417us/step - loss: 13814.5286 - val_loss: 12826.1274\n",
      "Epoch 924/1000\n",
      "2304/2304 [==============================] - 1s 419us/step - loss: 14904.2527 - val_loss: 13254.0662\n",
      "Epoch 925/1000\n",
      "2304/2304 [==============================] - 1s 401us/step - loss: 14411.9720 - val_loss: 12841.3170\n",
      "Epoch 926/1000\n",
      "2304/2304 [==============================] - 1s 406us/step - loss: 14629.6957 - val_loss: 15033.8485\n",
      "Epoch 927/1000\n",
      "2304/2304 [==============================] - 1s 416us/step - loss: 14348.2908 - val_loss: 14876.2320\n",
      "Epoch 928/1000\n",
      "2304/2304 [==============================] - 1s 420us/step - loss: 14075.3151 - val_loss: 13959.1821\n",
      "Epoch 929/1000\n",
      "2304/2304 [==============================] - 1s 409us/step - loss: 14288.5601 - val_loss: 12458.3268\n",
      "Epoch 930/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14819.0479 - val_loss: 12861.2873\n",
      "Epoch 931/1000\n",
      "2304/2304 [==============================] - 1s 455us/step - loss: 13920.4318 - val_loss: 12759.2584\n",
      "Epoch 932/1000\n",
      "2304/2304 [==============================] - 1s 410us/step - loss: 14030.5567 - val_loss: 16690.3853\n",
      "Epoch 933/1000\n",
      "2304/2304 [==============================] - 1s 409us/step - loss: 14995.1577 - val_loss: 12408.4145\n",
      "Epoch 934/1000\n",
      "2304/2304 [==============================] - 1s 418us/step - loss: 14364.7210 - val_loss: 13108.9323\n",
      "Epoch 935/1000\n",
      "2304/2304 [==============================] - 1s 413us/step - loss: 14219.7713 - val_loss: 12570.9672\n",
      "Epoch 936/1000\n",
      "2304/2304 [==============================] - 1s 426us/step - loss: 14441.0540 - val_loss: 12885.1096\n",
      "Epoch 937/1000\n",
      "2304/2304 [==============================] - 1s 421us/step - loss: 14052.5804 - val_loss: 12657.4459\n",
      "Epoch 938/1000\n",
      "2304/2304 [==============================] - 1s 445us/step - loss: 13923.9323 - val_loss: 13260.1057\n",
      "Epoch 939/1000\n",
      "2304/2304 [==============================] - 1s 440us/step - loss: 14013.6045 - val_loss: 13729.9309\n",
      "Epoch 940/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13959.4256 - val_loss: 12934.7212\n",
      "Epoch 941/1000\n",
      "2304/2304 [==============================] - 1s 429us/step - loss: 14320.5392 - val_loss: 13995.1145\n",
      "Epoch 942/1000\n",
      "2304/2304 [==============================] - ETA: 0s - loss: 14821.987 - 1s 402us/step - loss: 14817.3598 - val_loss: 12546.6118\n",
      "Epoch 943/1000\n",
      "2304/2304 [==============================] - 1s 400us/step - loss: 13632.6041 - val_loss: 12900.9206\n",
      "Epoch 944/1000\n",
      "2304/2304 [==============================] - 1s 392us/step - loss: 14375.1462 - val_loss: 12765.3758\n",
      "Epoch 945/1000\n",
      "2304/2304 [==============================] - 1s 378us/step - loss: 14128.5347 - val_loss: 14432.7357\n",
      "Epoch 946/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 14197.4131 - val_loss: 13281.8154\n",
      "Epoch 947/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 14080.5850 - val_loss: 12181.3528\n",
      "Epoch 948/1000\n",
      "2304/2304 [==============================] - 1s 384us/step - loss: 14324.9667 - val_loss: 12349.6915\n",
      "Epoch 949/1000\n",
      "2304/2304 [==============================] - 1s 399us/step - loss: 14012.5511 - val_loss: 13018.6412\n",
      "Epoch 950/1000\n",
      "2304/2304 [==============================] - 1s 390us/step - loss: 14255.0074 - val_loss: 15873.9080\n",
      "Epoch 951/1000\n",
      "2304/2304 [==============================] - 1s 412us/step - loss: 14717.7372 - val_loss: 12762.9510\n",
      "Epoch 952/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13974.3436 - val_loss: 12546.4765\n",
      "Epoch 953/1000\n",
      "2304/2304 [==============================] - 1s 372us/step - loss: 14234.0405 - val_loss: 13405.9529\n",
      "Epoch 954/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 14021.4645 - val_loss: 12466.7760\n",
      "Epoch 955/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 13925.6977 - val_loss: 13453.8253\n",
      "Epoch 956/1000\n",
      "2304/2304 [==============================] - 1s 369us/step - loss: 14474.5282 - val_loss: 12504.4543\n",
      "Epoch 957/1000\n",
      "2304/2304 [==============================] - 1s 372us/step - loss: 13990.5396 - val_loss: 12301.0943\n",
      "Epoch 958/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 13936.6069 - val_loss: 13217.6736\n",
      "Epoch 959/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 14229.4402 - val_loss: 12295.4087\n",
      "Epoch 960/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 14244.5842 - val_loss: 12878.1249\n",
      "Epoch 961/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 13966.3603 - val_loss: 13099.1012\n",
      "Epoch 962/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14448.5880 - val_loss: 13052.2593\n",
      "Epoch 963/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 13804.9836 - val_loss: 13043.3453\n",
      "Epoch 964/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14432.2674 - val_loss: 12421.3675\n",
      "Epoch 965/1000\n",
      "2304/2304 [==============================] - 1s 389us/step - loss: 13866.9203 - val_loss: 12710.0364\n",
      "Epoch 966/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14118.5367 - val_loss: 12608.4325\n",
      "Epoch 967/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13863.9051 - val_loss: 12497.9934\n",
      "Epoch 968/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 14055.5219 - val_loss: 12798.6343\n",
      "Epoch 969/1000\n",
      "2304/2304 [==============================] - 1s 382us/step - loss: 14203.0176 - val_loss: 12626.2237\n",
      "Epoch 970/1000\n",
      "2304/2304 [==============================] - 1s 370us/step - loss: 14280.9816 - val_loss: 12754.1671\n",
      "Epoch 971/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 13951.1702 - val_loss: 12712.6477\n",
      "Epoch 972/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14304.2816 - val_loss: 17329.0146\n",
      "Epoch 973/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 15169.8071 - val_loss: 12271.1659\n",
      "Epoch 974/1000\n",
      "2304/2304 [==============================] - 1s 384us/step - loss: 14481.7509 - val_loss: 13241.9281\n",
      "Epoch 975/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 13924.4217 - val_loss: 13457.2602\n",
      "Epoch 976/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 14402.3264 - val_loss: 12988.4250\n",
      "Epoch 977/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 13917.5887 - val_loss: 14214.5680\n",
      "Epoch 978/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 13851.6644 - val_loss: 14613.6863\n",
      "Epoch 979/1000\n",
      "2304/2304 [==============================] - 1s 375us/step - loss: 13638.6078 - val_loss: 12895.8128\n",
      "Epoch 980/1000\n",
      "2304/2304 [==============================] - 1s 371us/step - loss: 14048.2012 - val_loss: 15794.4410\n",
      "Epoch 981/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14248.7375 - val_loss: 12595.4897\n",
      "Epoch 982/1000\n",
      "2304/2304 [==============================] - 1s 378us/step - loss: 13976.9222 - val_loss: 12944.9743\n",
      "Epoch 983/1000\n",
      "2304/2304 [==============================] - 1s 380us/step - loss: 13878.1132 - val_loss: 14461.1452\n",
      "Epoch 984/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 13750.8418 - val_loss: 13647.0555\n",
      "Epoch 985/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 13821.2843 - val_loss: 15657.8466\n",
      "Epoch 986/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2304/2304 [==============================] - 1s 387us/step - loss: 13951.3668 - val_loss: 12503.4262\n",
      "Epoch 987/1000\n",
      "2304/2304 [==============================] - 1s 374us/step - loss: 13732.6873 - val_loss: 12674.2793\n",
      "Epoch 988/1000\n",
      "2304/2304 [==============================] - 1s 384us/step - loss: 14143.0375 - val_loss: 12801.1951\n",
      "Epoch 989/1000\n",
      "2304/2304 [==============================] - 1s 376us/step - loss: 14586.6882 - val_loss: 13891.1528\n",
      "Epoch 990/1000\n",
      "2304/2304 [==============================] - 1s 376us/step - loss: 14043.9540 - val_loss: 12848.9969\n",
      "Epoch 991/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14709.4745 - val_loss: 13196.8980\n",
      "Epoch 992/1000\n",
      "2304/2304 [==============================] - 1s 379us/step - loss: 13989.1206 - val_loss: 13358.9111\n",
      "Epoch 993/1000\n",
      "2304/2304 [==============================] - 1s 373us/step - loss: 13895.6108 - val_loss: 12177.6148\n",
      "Epoch 994/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 13983.3783 - val_loss: 12892.7427\n",
      "Epoch 995/1000\n",
      "2304/2304 [==============================] - 1s 377us/step - loss: 14490.0895 - val_loss: 14749.1190\n",
      "Epoch 996/1000\n",
      "2304/2304 [==============================] - 1s 376us/step - loss: 14125.6700 - val_loss: 13738.9878\n",
      "Epoch 997/1000\n",
      "2304/2304 [==============================] - 1s 388us/step - loss: 14066.8977 - val_loss: 12453.9828\n",
      "Epoch 998/1000\n",
      "2304/2304 [==============================] - 1s 388us/step - loss: 13551.5174 - val_loss: 14619.2152\n",
      "Epoch 999/1000\n",
      "2304/2304 [==============================] - 1s 386us/step - loss: 13681.4783 - val_loss: 12727.4434\n",
      "Epoch 1000/1000\n",
      "2304/2304 [==============================] - 1s 383us/step - loss: 14083.6308 - val_loss: 13065.0160\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "# Initialising the ANN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu',input_dim = 174))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(output_dim = 25, init = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(output_dim = 50, init = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(output_dim = 1, init = 'he_uniform'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss=root_mean_squared_error, optimizer='Adamax')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train.values, y_train.values,validation_split=0.20, batch_size = 10, nb_epoch = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_pred=classifier.predict(df_Test.drop(['SalePrice'],axis=1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
